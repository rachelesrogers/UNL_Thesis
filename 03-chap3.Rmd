# Jury Perception Revisited: This Time with Caricatures {#study2}

## Background


### Study 1 and Scale Compression

The results from the initial study found in Chapter \@ref(study1) call into question the use of Likert response scales in this scenario, as well as the use of a transcript testimony format.

Responses pertaining to the credibility of the expert, as well as the reliability and scientificity of the evidence, suffered from scale compression when a Likert scale was used - participants indicated overall confidence in credibility, reliability, and scientificity by mainly selecting the two highest categories of each scale.
This lack of variation in scale responses makes it difficult to discern potential differences between treatment conditions.
Due to this difficulty, we conducted a micro study in order to compare various response types, in order to determine substitute questions that may be more sensitive to scenario differences.
Additional changes include the addition of jury instructions on the part of the judge, instructing members of the jury to treat the firearms examiner and algorithm developer as they would any other witness.
Additional cross examination testimony with regards to the firearms examiner's inability to specifically tie the defendant to the crime scene is included as well.
The transcript for the second study can be found in Appendix \@ref(study-2-changes).

Some participants left confused comments with regards to who the witnesses were testifying for.
The transcript format may lend an air of impartiality to the witnesses, when they are in fact testifying for a specific side in the case.
Also, the format of the testimony transcripts does not clearly identify the speaker with each line, instead using "Q:" and "A:" in most cases, as shown in Appendix \@ref(study-2-changes).
This lack of visuals for tracking speakers is not representative of the courtroom setting, and may have contributed to the confusion expressed by a participant.
Due to this potential issue, we strove to develop a general tool that can be used in online courtroom studies, making it easier to track speakers, and with versatility in terms of individual characteristics.

In order to minimize the chance of confounding typos as seen in Study 1, one master file is used with all lines of testimony, labelled by the scenario in which the testimony occurs.
Thus, there is no longer multiple files of repeated text.
Unique identification is used throughout the database files instead of relying on unique fingerprints, so the demographics section can more easily be linked to the final results.

### Study Visualization

Appendix \@ref(study-2-changes) shows the characters that have been developed for this study, as well as a screenshot of the study format.
These characters were drawn so that the clothes and heads can be interchanged, providing a wide variety of characters for potential scenarios.
One difficulty in including drawn figures with realistic skin tones and figures is the influence of perceived race or gender on the participants' judgements.
@ImplicitRaceAttitudes found a relationship between implicit racial bias and the perceived trustworthiness of individuals based on images of black and white males.
They also found that 80% of participants exhibited pro-white implicit bias.
Because of this potential bias introduced by visual figures, we plan to conduct a study in order to determine how these figures are perceived.

## Micro Study on Response Type

To investigate a which response type may be most informative for this study and to troubleshoot the use of figures and speech bubble format, we conducted a smaller micro study using various response types.

### Methods

#### Study Format

Participants were presented with the same scenario described in Study 1.
In this case, however, the only factor that was changes was the conclusion of the firearms examiner: either a match or not a match.
In all conditions, the algorithm was absent and there were no images.
The testimony largely followed that of Study 1, aside from differences in the format and additional testimony described above.
In this case, it was also explicitly state that the testimony did not reflect all evidence presented in the case, because in the non match condition there may not be enough evidence to bring the case to trial.

At the end of the testimony, the participants were asked a variety of questions regarding the strength of evidence in the case.
Questions of probability, strength of evidence, and decision to convict were also asked in Study 1.
They were asked to evaluate the probability that the defendant committed the crime, both with a visible probability scale (allowing the participants to select the exact probability value) and with a non-visible scale (only the numbers of 0 and 100 were available on the extremes of the scale).
The strength of evidence was a Likert scale with values from "Not at all strong" to "Extremely strong" with nine points.
In terms of conviction, participants were reminded of the decision criterion of "beyond a reasonable doubt" when making a decision in a criminal trial, and asked if they would choose to convict.

New questions for this micro study asked for individuals to give their opinion of the guilt of the defendant, as well as assessing the chances that the defendant committed the crime, how much they would be willing to bet that the defendant was either innocent or guilty, and their opinion of the defendant.
In addition to a question regarding whether or not the participant would choose to convict, we also asked the participants to give their personal opinion on the guilt of the defendant.
This provides a second threshold for assessing the strength of evidence, aside from the "beyond a reasonable doubt" standard.
Two different questions were asked with regards to the chances that the defendant committed the crime. 
One was in a multiple choice format, with extreme values of "Impossible to be guilty" and "Certain to be guilty", and intermediate values ranging from "About 1 chance in 10,000" to "About 9,999 chances in 10,000" with denominator values changing by a decimal place for each choice, and a middle value of "1 chance in 2".
This format was taken from @thompsonLayUnderstanding's study of DNA, which consisted of larger scaled values (up to 1 in 10 million).
The second question allowed participants to select both the numerator and denominator: "About ___ chance(s) in ___".
The format of the numeric chance of guilt question depends on the participant's opinion of guilt.
If the participant thought that the defendant was guilty, they were asked to provide the chance that the defendant was innocent.
If the participant thought that the defendant was innocent, they were asked to provide the chance that the defendant was guilty.
In both cases, the numerator had to be less than or equal to the denominator.
Similarly, if individuals thought that the defendant was guilty, they were asked how much they were willing to be that the defendant was guilty, if hypothetically researchers provided them with \$50 and they would double their money if they were correct, and vice versa.
A final new question was open ended, and asked participants to provide their opinion of the defendant.

Individuals were first asked to provide their opinion of the defendant, their conviction decision, and their personal opinion of the guilt of the defendant.
All other questions were randomized in a way that guaranteed the two probability questions and the two chance questions were not asked directly following each other.


#### Prolific

```{r echo=FALSE, warning=FALSE, message=FALSE}

library(readr)
microstudy <- read_csv("data/microstudy_cleanish_results.csv")

microstudy_clean <- microstudy %>% dplyr::filter(check=="9mm")

```

Participants were recruited in a similar manner as Study 1 in terms of the representative sample and self-screened jury requirements through Prolific.
In the first part of the study, some individuals encountered technical issues.
These technical issues appeared to happen to more individuals in the match condition compared to the non match condition, with a total of `r sum(microstudy$conclusion.x=="Match")` individuals in the match condition and `r sum(microstudy$conclusion.x=="NoMatch")` participants in the non-match condition, for a total of `r dim(microstudy)[1]` participants.
Participants were paid \$4.00 with a median completion time of 14 minutes and 47 seconds according to Prolific, for an average reward of \$16.23 per hour.
Figure \@ref(fig:completiontime2) shows the time spent after the completion of the first demographics page to the completion of the final results page.
Because it does not include the informed consent and the time to complete the first demographics page, its time estimates appear to be less than those found via Prolific.


```{r}
#| completiontime2,
#| fig.cap= "Completion Time by Condition",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE

microstudy$completion_time <- microstudy$actual_time3-microstudy$actual_time1

ggplot(microstudy, aes(x = completion_time, fill=conclusion.x)) +
    geom_density(alpha=0.75, color=NA) +
  ggtitle("Histogram of Completion Time") +
  xlab("Completion Time in Minutes")+
  scale_fill_manual(name="Conclusion", values = c("#FF8E00", "#037AC7"))+
  theme_bw()


```

### Results

#### Participants

Of the `r dim(microstudy)[1]` participants, `r sum(microstudy$gender=="Male")` participants identified as male, `r sum(microstudy$gender=="Female")` participants identified as female, and `r sum(microstudy$gender=="Other/non-binary")` participants identified as other or non-binary. 
The categories of "Male" and "Female" are currently more associated with sex than with gender, and this categorization will be relabeled in future studies.
The median age category was 46 - 55.
Age and gender are shown in Figure \@ref(fig:demographics2).
Individuals were asked a single attention check question with regards to the caliber of gun used in the attempted robbery.
`r dim(microstudy_clean)[1]` participants passed the attention check, meaning that only `r sum(microstudy$check!="9mm")` participants failed the attention check, and will not be included in the analysis.


```{r}
#| demographics2,
#| fig.cap= "Demographic Information",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE

microstudy$age = factor(
  microstudy$age,
  levels = c(
    "18 - 25",
    "26 - 35",
    "36 - 45",
    "46 - 55",
    "56 - 65",
    "Over 65"
  )
)

  ggplot(microstudy,
         aes(x = age, fill = gender)) +
  geom_bar(mapping = aes(y = after_stat(count), group = gender),
           position = position_dodge(preserve = "single"), color="black") +
  #  geom_histogram(stat="count", position="dodge")+
  ggtitle("Algorithm Expert Testimony") +
  scale_fill_manual(values = c("#E69F00", "#009E73", "#F0E442")) +
  theme_bw()+
  theme(axis.title.x = element_blank())

```
#### Questions from Study 1

`r round(sum(microstudy_clean$guilty=="Yes" & microstudy_clean$conclusion.x=="Match")/sum(microstudy_clean$conclusion.x=="Match")*100, 2)`\% (or `r sum(microstudy_clean$guilty=="Yes" & microstudy_clean$conclusion.x=="Match")` out of `r sum(microstudy_clean$conclusion.x=="Match")`) individuals who received the match condition chose to convict, while `r round(sum(microstudy_clean$guilty=="Yes" & microstudy_clean$conclusion.x=="NoMatch")/sum(microstudy_clean$conclusion.x=="NoMatch")*100, 2)`\% (or `r sum(microstudy_clean$guilty=="Yes" & microstudy_clean$conclusion.x=="NoMatch")` out of `r sum(microstudy_clean$conclusion.x=="NoMatch")`) participants who received the non-match condition chose to convict.
This is a slightly lower proportion of individuals choosing to convict than that seen in the Match condition in the original study, although there is no algorithm present in this case.

Figure \@ref(fig:strength2) shows participant responses to the strength of evidence in this study.
As can be seen, those in the non-match category tended to choose the smallest value for the strength of evidence ("Not at all strong"), while in the case of the match condition, individuals tended to distribute their views of the strength of evidence more evenly.
This graph resembles the strength of evidence results from the initial study.
While not as dramatic as the scale compression for questions of reliability, credibility, and scientificity, the non-match results for strength of evidence do appear to show a scale limitation in the way that individuals tended to select the lowest category.

```{r}
#| strength2,
#| fig.cap= "Microstudy Strength of Evidence",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE

microstudy_clean$strength = factor(
  microstudy_clean$strength,
  levels = c(
    "1 <br/> Not at all strong",
    "2",
    "3",
    "4",
    "5 <br/> Moderately strong",
    "6",
    "7",
    "8",
    "9 <br/> Extremely strong"
  )
)

ggplot(microstudy_clean) +
  geom_bar(aes(x=strength, fill=conclusion.x), position="dodge") +
  ggtitle("What is the Strength of Evidence against the Defendant?") +
  scale_fill_manual(values = c("grey80","seagreen"), name="Condition")+
  ylab("Count")+
  xlab("Strength")+
  theme_bw()+
  scale_x_discrete(labels = wrap_format(10))


```

Figure \@ref(fig:prob2) demonstrates the participants' selected probabilities that the defendant committed the crime.
As in the case of the strength of evidence, the graph resembles the probability graph found in Study 1, where there is a higher peak of extreme values for the non-match conditions than for the match condition.
There does not appear to be much difference in the density curves based on the visibility of the probability scale.

```{r}
#| prob2,
#| fig.cap= "Probability Cole Committed Crime",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE

colors <-  c("Hidden"="red", "Visible"="grey")

ggplot(microstudy_clean) +
  geom_density(alpha=0.75, aes(x=prob_hide, fill="Hidden")) +
  geom_density(alpha=0.75, aes(x=prob_vis, fill="Visible")) +
  ggtitle("Probability Cole Commited the Crime") +
  scale_fill_manual(values = colors, name="Probability")+
  ylab("Density")+
  xlab("Probability")+
  facet_grid(.~conclusion.x)+
  theme_bw()


```

`r round(sum(microstudy_clean$opinion_guilt=="Yes" & microstudy_clean$conclusion.x=="Match")/sum(microstudy_clean$conclusion.x=="Match")*100, 2)`\% (or `r sum(microstudy_clean$opinion_guilt=="Yes" & microstudy_clean$conclusion.x=="Match")` out of `r sum(microstudy_clean$conclusion.x=="Match")`) individuals who received the match condition thought the defendant was guilty, while `r round(sum(microstudy_clean$guilty=="Yes" & microstudy_clean$conclusion.x=="NoMatch")/sum(microstudy_clean$conclusion.x=="NoMatch")*100, 2)`\% (or `r sum(microstudy_clean$guilty=="Yes" & microstudy_clean$conclusion.x=="NoMatch")` out of `r sum(microstudy_clean$conclusion.x=="NoMatch")`) participants who received the non-match condition thought the defendant was guilty.
Figure \@ref(fig:opinionguilt) shows the comparison between the participant's decision to convict and their personal opinion.
Approximately half of the participant in the match condition who chose not to convict thought the defendant was in fact guilty.

```{r}
#| opinionguilt,
#| fig.cap= "Comparison of opinions of guilt and choice to convict",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE


ggplot(microstudy_clean) +
  geom_bar(aes(x=guilty, fill=opinion_guilt), position="dodge") +
  ggtitle("") +
  scale_fill_manual(values = c("#D81B60","#004D40"), name="Opinion", labels=c("Innocent","Guilty"))+
  ylab("Count")+
  xlab("Convict?")+
  facet_grid(.~conclusion.x)+
  theme_bw()

```

Figure \@ref(fig:betting) indicates how much participants said they would be willing to bet that the defendant was either guilty or innocent, if provided with \$50.
If the participant indicated that they thought the defendant was innocent, they were asked how much they would be willing to bet that the defendant was innocent, and vice versa.
Two individuals did not answer the question, while three individuals selected values larger than 50: two in the non-match condition who thought Cole was innocent (\$58 and \$100), and one in the match condition who thought Cole was guilty (\$100).
This figure indicates that most people who thought Cole was innocent in the non-match condition were willing to bet the full amount.
It also appears that people tended to select values around multiples of 5, and those in the match condition selected less extreme values (for both those who thought the defendant was guilty and those who thought the defendant was innocent) than what is seen in those with the non-match condition who thought the defendant was innocent.
In this way, the betting response is similar both to the strength of evidence response and the probability of committing the crime response.

```{r}
#| betting,
#| fig.cap= "If the researchers provided 50 dollars, how much would you be willing to bet?",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE

microstudy_clean$bet<- NA

microstudy_clean[!is.na(microstudy_clean$guilt_bet),]$bet<- 
  microstudy_clean[!is.na(microstudy_clean$guilt_bet),]$guilt_bet

microstudy_clean[!is.na(microstudy_clean$innocent_bet),]$bet<- microstudy_clean[!is.na(microstudy_clean$innocent_bet),]$innocent_bet

ggplot(microstudy_clean) +
  geom_histogram(aes(x=bet, fill=opinion_guilt), binwidth=5, color="black",
           position = position_dodge(preserve = "single")) +
  ggtitle("How much would you bet that the Defendant is...") +
  scale_fill_manual(values = c("#D81B60","#004D40"), name="", labels=c("Innocent","Guilty"))+
  ylab("Count")+
  xlab("Bet Amount")+
  xlim(c(0,50))+
  facet_grid(conclusion.x~.)+
  theme_bw()


```

The remaining questions relate to the chance that the defendant committed the crime.
One question, shown in Figure \@ref(fig:fixedlike), allowed participants to select the chance that the defendant committed the crime from a multiple choice scale.
Based on the scale used, this question remained the same regardless of the participant's opinion on the guilt of the defendant.
This scale does not provide a linear distance between intervals, but instead changes by multiples of 10 in the denominator (ex. one category is 1 in 10, and the next category is 1 in 100).
The exception is the endpoints, which are "Impossible to be guilty" and "Certain to be guilty", as well as the midpoint of 1 chance in 2.
In this case, the non-match scale is not encountering the ceiling or floor effect that has been seen in previous scales, as participants did not overwhelmingly select the lowest value.
Instead, participants are distributed mainly throughout the lower half of the scale, while those in the match condition tended to be a little closer to the center.
Thus, the multiple choice chance scale appears to have less scale compression than seen previously in the other response types.

```{r}
#| fixedlike,
#| fig.cap= "Multiple Choice Chance",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE

microstudy_clean$fixed_like = factor(
  microstudy_clean$fixed_like,
  levels = c(
    "Impossible that he is guilty",
    "About 1 chance in 10,000",
    "About 1 chance in 1,000",
    "About 1 chance in 100",
    "About 1 chance in 10",
    "1 chance in 2 (fifty-fifty chance)",
    "About 9 chances in 10",
    "About 99 chances in 100",
    "About 999 chances in 1,000",
    "About 9,999 chances in 10,000",
    "Certain to be guilty"
  )
)

ggplot(microstudy_clean) +
  geom_bar(aes(x=fixed_like, fill=conclusion.x), position="dodge") +
  ggtitle("What is the Chance that the Defendant is Guilty?") +
  scale_fill_manual(values = c("grey80","seagreen"), name="Condition")+
  ylab("Count")+
  xlab("Chance")+
  theme_bw()+
  scale_x_discrete(labels = wrap_format(10))


```

A final question asks individuals to provide a numerical chance that the defendant is either innocent or guilty, depending on their expressed opinion.
If the participant thought that the defendant was innocent, they were asked to supply the chance that the defendant was guilty, and vice versa.
Their responses were limited so that the numerator was smaller than the denominator, resulting in a range of 0 to 1.
These results are shown in Figure \@ref(fig:freelike).
As seen in previous graphs, in the case of the non-match condition, those who thought the defendant was innocent gave small chances that the defendant had in fact committed the crime.
Note that this graph consists of the density in each group.
In the case of the match condition, those who thought the defendant was guilty tended to give lower chances that the defendant had in fact committed the crime, although it is not as extreme as the non-match condition case.

```{r}
#| freelike,
#| fig.cap= "Free Response Chance",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE

microstudy_clean$likelihood<- NA

microstudy_clean[!is.na(microstudy_clean$innocent_free_num) &
                !is.na(microstudy_clean$innocent_free_denom),]$likelihood<-
  microstudy_clean[!is.na(microstudy_clean$innocent_free_num) &
                  !is.na(microstudy_clean$innocent_free_denom),]$innocent_free_num/
  microstudy_clean[!is.na(microstudy_clean$innocent_free_num) & 
                  !is.na(microstudy_clean$innocent_free_denom),]$innocent_free_denom

microstudy_clean[!is.na(microstudy_clean$guilt_free_num) &
                !is.na(microstudy_clean$guilt_free_denom),]$likelihood<-
  microstudy_clean[!is.na(microstudy_clean$guilt_free_num) &
                  !is.na(microstudy_clean$guilt_free_denom),]$guilt_free_num/
  microstudy_clean[!is.na(microstudy_clean$guilt_free_num) & 
                  !is.na(microstudy_clean$guilt_free_denom),]$guilt_free_denom

ggplot(microstudy_clean) +
  geom_density(alpha=0.75, aes(x=likelihood, fill=opinion_guilt), position="dodge") +
  ggtitle("What is the chance that the defendant is...") +
  scale_fill_manual(values = c("#D81B60","#004D40"), name="", labels=c("Guilty","Innocent"))+
 # ylab("Count")+
  xlab("Chance")+
  facet_grid(.~conclusion.x)+
  #scale_x_continuous(trans='log10')+
  theme_bw()


```

Based on the results shown in Figure \@ref(fig:fixedlike), it seems that the results from this free chance scale may benefit from a transformation of the scale.
The log scale transformation is shown in \@ref(fig:freelike10).
This scale transformation shifted the observations from the far left side of the graph to the right side of the graph.
The distribution of the scale is more spread out than that shown in Figure \@ref(fig:freelike), and may lend itself better to analysis.

```{r}
#| freelike10,
#| fig.cap= "Free Response Chance, Log 10 Scale",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE

ggplot(microstudy_clean) +
  geom_density(alpha=0.75, aes(x=likelihood, fill=opinion_guilt), position="dodge") +
  ggtitle("What is the chance that the defendant is...") +
  scale_fill_manual(values = c("#D81B60","#004D40"), name="", labels=c("Guilty","Innocent"))+
 # ylab("Count")+
  xlab("Chance")+
  facet_grid(.~conclusion.x)+
  scale_x_continuous(trans='log10')+
  theme_bw()


```

#### Scale Comparison

##### Chance Comparison

Consistency across response types is another important aspect of this study.
If different question types result in responses that are inconsistent, it would be difficult to tell which questions truly capture the attitudes of the participants, in order to most accurately answer the research questions.
As mentioned in the previous literature review, there have been studies to suggest that individuals may struggle with the interpretation of chance scales.
Questions of how much a participant is willing to bet may also depend on their personal feel for risk, and betting hypothetical money may have different results than betting real money, or betting money for someone else.
\authorcol{There is a source for making decisions for others somewhere, and it may have had something to do with betting or something to do with plea deals. TBD}
Because individuals may be influenced by which scale they see first, the order of the questions were randomized and recorded, so that the orders can be compared.

Figure \@ref(fig:likecomp1) shows the comparison of the multiple choice chance responses to the numeric chance responses, in the case that the participants thought the defendant was innocent.
Because these individuals thought that the defendant was innocent, there are few responses higher than a "fifty-fifty chance".
The red dots represent the actual value represented by the multiple choice chance (for example, the red dot for "About 1 chance in 10" is located at the y-value of 0.10).
This allows for comparison on the consistency between the multiple choice and the numeric scales.
For values of "1 chance in 2" and "About 1 chance in 10", the responses seem fairly consistent - however, it is difficult to tell if these values are consistent for smaller values, because they are seen as small on the linear scale.

```{r}
#| likecomp1,
#| fig.cap= "Innocent Chance Comparison",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE


set_values <- data.frame(fixed_like=c(    "Impossible that he is guilty",
                                          "About 1 chance in 10,000",
                                          "About 1 chance in 1,000",
                                          "About 1 chance in 100",
                                          "About 1 chance in 10",
                                          "1 chance in 2 (fifty-fifty chance)",
                                          "About 9 chances in 10",
                                          "About 99 chances in 100",
                                          "About 999 chances in 1,000",
                                          "About 9,999 chances in 10,000",
                                          "Certain to be guilty"),
                         value=c(0,1/10000,1/1000,1/100,1/10,0.5,9/10,99/100,999/1000,9999/10000,1))
clean_results_merged<- dplyr::left_join(microstudy_clean, set_values)
clean_results_merged$fixed_like = factor(
  microstudy_clean$fixed_like,
  levels = c(
    "Impossible that he is guilty",
    "About 1 chance in 10,000",
    "About 1 chance in 1,000",
    "About 1 chance in 100",
    "About 1 chance in 10",
    "1 chance in 2 (fifty-fifty chance)",
    "About 9 chances in 10",
    "About 99 chances in 100",
    "About 999 chances in 1,000",
    "About 9,999 chances in 10,000",
    "Certain to be guilty"
  )
)
ggplot(clean_results_merged, aes(x=fixed_like))+ #,fill=conclusion
  geom_point(aes(y=value),color="red",size=5,alpha=0.5)+
  ggtitle("Chance for those who thought Cole was innocent") +
  geom_jitter(aes(y=(guilt_free_num/guilt_free_denom)),
    # position = position_jitterdodge(
    #   jitter.width = 0.2,
    #   #jitter.height = 0.4,
    #   dodge.width = 1
    # ),
    size = 1
  ) +
  geom_boxplot(aes(y=(guilt_free_num/guilt_free_denom)),
               position = position_dodge(1),
               alpha = 0.5,
               outlier.shape = NA)+ 
  ylab("Open Response Chance")+
  xlab("Closed Response Chance")+
#  scale_y_continuous(trans='log10')+
  scale_x_discrete(labels = wrap_format(10))

```

This transformation is shown in Figure \@ref(fig:likecomp1scale).
From this transformed scale, there still appears to be consistency between when participants choose their own chance numerically and when they were offered a multiple choice.
There does, however, appear to be a difference in those who selected "Impossible that he is guilty" from the multiple choice scale.
Many of the numerical responses appear to be more consistent to "About 1 chance in 10,000" than the value of 0 that would indicate impossibility.

```{r}
#| likecomp1scale,
#| fig.cap= "Innocent Chance Comparison Log 10 Scale",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE

ggplot(clean_results_merged, aes(x=fixed_like))+ #,fill=conclusion
  geom_point(aes(y=value),color="red",size=5,alpha=0.5)+
  ggtitle("Chance for those who thought Cole was innocent") +
  geom_jitter(aes(y=(guilt_free_num/guilt_free_denom)),
    # position = position_jitterdodge(
    #   jitter.width = 0.2,
    #   #jitter.height = 0.4,
    #   dodge.width = 1
    # ),
    size = 1
  ) +
  geom_boxplot(aes(y=(guilt_free_num/guilt_free_denom)),
               position = position_dodge(1),
               alpha = 0.5,
               outlier.shape = NA)+ 
  ylab("Open Response Chance")+
  xlab("Closed Response Chance")+
  scale_y_continuous(trans='log10')+
  scale_x_discrete(labels = wrap_format(10))

```

This same procedure can be repeated for those who thought the defendant was guilty, as shown in Figure \@ref(fig:likecomp2).
In this case, because individuals who thought the defendant was guilty were asked to supply the chance that the defendant did not commit the crime, their numerical chance was changed to the chance that the defendant did commit the crime by subtracting their provided chance estimate from 1.
In a reverse of the chance for those who thought Cole was innocent, in this case most responses are at or above "1 chance in 2".
Even without a transformation, it can be seen that there is a large spread of those who selected "Certain to be guilty", and that those who selected "fifty-fifty chance" tended to select higher chances of guilt when they were free to choose their own response, while those who selected "About 9 chances in 10" tended to align well between the numerical and multiple choice options.

The reduced consistency seen in the guilty chance may related to the change in the question wording, where the multiple choice question considers the chance of guilt, while their numeric chance considered the chance of innocence.

```{r}
#| likecomp2,
#| fig.cap= "Guilty Chance Comparison",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE

ggplot(clean_results_merged, aes(x=fixed_like))+ #,fill=conclusion
  geom_point(aes(y=value),color="red",size=5,alpha=0.5)+
  ggtitle("Chance for those who thought Cole was guilty") +
  geom_jitter(aes(y=(1-innocent_free_num/innocent_free_denom)),
             # position = position_jitterdodge(
             #   jitter.width = 0.2,
             #   #jitter.height = 0.4,
             #   dodge.width = 1
             # ),
             size = 1
  ) +
  geom_boxplot(aes(y=(1-innocent_free_num/innocent_free_denom)),
               position = position_dodge(1),
               alpha = 0.5,
               outlier.shape = NA)+ 
  ylab("Open Response Chance")+
  xlab("Closed Response Chance")+
  scale_x_discrete(labels = wrap_format(10))

```

```{r}
#| likecomp2scale,
#| fig.cap= "Guilty Chance Comparison",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= FALSE,
#| warning= FALSE,
#| message= FALSE

ggplot(clean_results_merged, aes(x=fixed_like))+ #,fill=conclusion
  geom_point(aes(y=value),color="red",size=5,alpha=0.5)+
  ggtitle("Chance for those who thought Cole was guilty") +
  geom_jitter(aes(y=(1-innocent_free_num/innocent_free_denom)),
             # position = position_jitterdodge(
             #   jitter.width = 0.2,
             #   #jitter.height = 0.4,
             #   dodge.width = 1
             # ),
             size = 1
  ) +
  geom_boxplot(aes(y=(1-innocent_free_num/innocent_free_denom)),
               position = position_dodge(1),
               alpha = 0.5,
               outlier.shape = NA)+ 
    scale_y_continuous(trans='sqrt')+
  ylab("Open Response Chance")+
  xlab("Closed Response Chance")+
  scale_x_discrete(labels = wrap_format(10))

```

Similar to the figures above, a comparison graph can be made to compare the multiple choice chance values to the probability scales. 
This scale comparison is shown in Figure \@ref(fig:likeprob).
In the case of the probabilities, individuals were only able to select integers between 0 and 100, meaning that this scale would not translate to the more extreme values of the multiple choice chance scale (outside of the values of "About 1 in 100" and "About 99 in 100").
For values that can map from the probability scale to the chance scale, the values appear to be more spread out than those in the numerical chance scale, and those who selected "About 1 chance in 10" on the multiple choice scale tended to select larger chances.

```{r}
#| likeprob,
#| fig.cap= "Probability and Chance Comparison",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE

ggplot(clean_results_merged, aes(x=fixed_like))+ #,fill=conclusion
  geom_point(aes(y=value),color="red",size=5,alpha=0.5)+
  ggtitle("Probability vs. Chance That Cole is Guilty") +
  geom_jitter(aes(y=(prob_vis/100)),
             # position = position_jitterdodge(
             #   jitter.width = 0.2,
             #   #jitter.height = 0.4,
             #   dodge.width = 1
             # ),
             size = 1
  ) +
  geom_boxplot(aes(y=(prob_vis/100)),
               position = position_dodge(1),
               alpha = 0.5,
               outlier.shape = NA)+ 
  ylab("Visible Probability")+
  xlab("Closed Response Chance")+
  scale_x_discrete(labels = wrap_format(10))

```

```{r}
#| likeprobcon,
#| fig.cap= "Probability and Chance Comparison",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE

microstudy_clean$likelihood_rev<- NA

microstudy_clean[!is.na(microstudy_clean$innocent_free_num) &
                !is.na(microstudy_clean$innocent_free_denom),]$likelihood_rev<-1-(
  microstudy_clean[!is.na(microstudy_clean$innocent_free_num) &
                  !is.na(microstudy_clean$innocent_free_denom),]$innocent_free_num/
  microstudy_clean[!is.na(microstudy_clean$innocent_free_num) & 
                  !is.na(microstudy_clean$innocent_free_denom),]$innocent_free_denom)

microstudy_clean[!is.na(microstudy_clean$guilt_free_num) &
                !is.na(microstudy_clean$guilt_free_denom),]$likelihood_rev<-
  microstudy_clean[!is.na(microstudy_clean$guilt_free_num) &
                  !is.na(microstudy_clean$guilt_free_denom),]$guilt_free_num/
  microstudy_clean[!is.na(microstudy_clean$guilt_free_num) & 
                  !is.na(microstudy_clean$guilt_free_denom),]$guilt_free_denom


ggplot(microstudy_clean, aes(x=likelihood_rev, color=opinion_guilt, y=prob_vis)) +
  geom_jitter(alpha=0.5) +
  ggtitle("Probability vs Chance") +
  scale_color_manual(values = c("#D81B60","#004D40"), name="Opinion", labels=c("Innocent","Guilty"))+
  ylab("Visible Probability")+
  xlab("Chance of Committing Crime")+
  facet_grid(.~conclusion.x)+
  theme_bw()

microstudy_clean$innocent_likelihood<- NA

microstudy_clean[!is.na(microstudy_clean$innocent_free_num) &
                !is.na(microstudy_clean$innocent_free_denom),]$innocent_likelihood<-(
  microstudy_clean[!is.na(microstudy_clean$innocent_free_num) &
                  !is.na(microstudy_clean$innocent_free_denom),]$innocent_free_num/
  microstudy_clean[!is.na(microstudy_clean$innocent_free_num) & 
                  !is.na(microstudy_clean$innocent_free_denom),]$innocent_free_denom)

microstudy_clean$guilt_likelihood<- NA

microstudy_clean[!is.na(microstudy_clean$guilt_free_num) &
                !is.na(microstudy_clean$guilt_free_denom),]$guilt_likelihood<-
  microstudy_clean[!is.na(microstudy_clean$guilt_free_num) &
                  !is.na(microstudy_clean$guilt_free_denom),]$guilt_free_num/
  microstudy_clean[!is.na(microstudy_clean$guilt_free_num) & 
                  !is.na(microstudy_clean$guilt_free_denom),]$guilt_free_denom

```

Figure \@ref(fig:likeprobcon) shows a comparison of the perceived probability that the defendant committed the crime compared to the perceived chance that the defendant is guilty.
In the case of the match condition, it can be seen that many individuals assigned a high probability that the defendant committed the crime which corresponded to a high chance of guilt, as shown by the cluster of observations in the top right corner of the graph.
Similarly, in the non-match condition, many individuals gave a low probability that the individual committed the crime and a low chance that the defendant was guilty.
The correlation between the probability and the chances of guilt is `r round(cor(microstudy_clean[!is.na(microstudy_clean$guilt_likelihood),]$prob_vis, microstudy_clean[!is.na(microstudy_clean$guilt_likelihood),]$guilt_likelihood),2)`,
while the correlation between the probability and the chances of innocence is `r round(cor(microstudy_clean[!is.na(microstudy_clean$innocent_likelihood),]$prob_vis, microstudy_clean[!is.na(microstudy_clean$innocent_likelihood),]$innocent_likelihood),2)`.
While there is a fairly strong correlation in the case of chances of guilt and probability, the correlation between the probability and the chances of innocence is weak.
This weak correspondence can be seen in the "Guilty" opinion observations in the graph above
When the chances are combined into a single variable, values can be seen across the entire probability scale.
The correlation between the probability and the combined chance responses is `r round(cor(microstudy_clean[!is.na(microstudy_clean$likelihood_rev),]$prob_vis, microstudy_clean[!is.na(microstudy_clean$likelihood_rev),]$likelihood_rev),2)`, which appears to be fairly strong.

Figure \@ref(fig:likeconvict) demonstrates the relationship between likelihood, probability, and the decision to convict.
In the non-match case, few individuals chose to convict.
In the match condition, those who chose to convict selected a probability above 50%, and tended to select values in the top right corner, which appears to be consistent with their conviction choice.
The clustering of values at around 1 on the chance scale may be due to compression in higher numbers, much like what was seen on the multiple choice question.


```{r}
#| likeconvict,
#| fig.cap= "Probability and Conviction Decision",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE

ggplot(microstudy_clean, aes(x=likelihood_rev, color=guilty, y=prob_vis)) +
  geom_jitter(alpha=0.85) +
  ggtitle("Probability vs Chance") +
  scale_color_manual(values = c("grey20", "plum1"), name="Convict?")+
  ylab("Visible Probability")+
  xlab("Chance of Committing Crime")+
  facet_grid(.~conclusion.x)+
  theme_bw()

```

##### Probability Comparison

Figure \@ref(fig:probcomp) shows the correspondence between the visible and hidden probabilities.
The values appear to be fairly 1:1.
In the case of the match condition, there appears to be a congregation of values at 90% when the scale is visible.
This is also reflected in the non-match condition, where there is a group of observations at 10%.
Otherwise, the observations appear to correspond fairly well.
The correlation between the probabilities is `r round(cor(microstudy_clean$prob_hide, microstudy_clean$prob_vis),2)`, indicating a strong relationship.

```{r}
#| probcomp,
#| fig.cap= "Probability and Chance Comparison",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE

ggplot(microstudy_clean, aes(x=prob_hide, color=opinion_guilt, y=prob_vis)) +
  geom_jitter(alpha=0.5) +
  ggtitle("Visible and Hidden Probability Comparison") +
  scale_color_manual(values = c("#D81B60","#004D40"), name="Opinion", labels=c("Guilty","Innocent"))+
  ylab("Visible Probability")+
  xlab("Hidden Probability")+
  scale_y_continuous(breaks = seq(0, 100, by = 10))+
  facet_grid(.~conclusion.x)+
  coord_fixed(ratio=1)+
  geom_abline(intercept = 0, slope = 1)+
  theme_bw()

```

Figure \@ref(fig:probbet) compares the amount that individuals were willing to bet to their assigned probability that the defendant had committed the crime.
In this case, there is not a straightforward correspondence.
The correlation is `r round(cor(microstudy_clean[!is.na(microstudy_clean$guilt_bet),]$prob_vis, microstudy_clean[!is.na(microstudy_clean$guilt_bet),]$guilt_bet),2)` in the case that the participants were asked to bet on if the defendant committed the crime, and `r round(cor(microstudy_clean[!is.na(microstudy_clean$innocent_bet),]$prob_vis, microstudy_clean[!is.na(microstudy_clean$innocent_bet),]$innocent_bet),2)` when participants were asked to bet on if the defendant did not commit the crime (where the betting procedure is as explained earlier).
This correlation is lower than seen between probability and the chance of committing the crime when both of the chances were combined.

```{r}
#| probbet,
#| fig.cap= "Betting and Probability Comparison",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE

ggplot(microstudy_clean, aes(x=bet, color=opinion_guilt, y=prob_vis)) +
  geom_jitter(alpha=0.75) +
  ggtitle("Betting and Probability Comparison") +
  scale_color_manual(values = c("#004D40","#D81B60"), name="Bet Defendant is...", labels=c("Innocent","Guilty"))+
  ylab("Visible Probability")+
  xlab("Amount (Dollars)")+
  scale_y_continuous(breaks = seq(0, 100, by = 10))+
  facet_grid(.~conclusion.x)+
  xlim(c(0,50))+
  theme_bw()

```

#### Demographic Comparison

Demographic information, such as income, race, gender, and education level, was collected on the participants.
This demographic information can be compared with the participants' responses.

##### Income
Figure \@ref(fig:probincome) explores a potential relationship between income and believed probability that the defendant committed the crime.
While there are generally low probabilities across all income levels for the non-match condition, in the match condition there appears to be higher probabilities on the higher and lower ends of the income scale, with lower assigned probabilities for those in the middle of the income scale for those who did not choose to convict.

```{r}
#| probincome,
#| fig.cap= "Income and Probability Comparison",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE

microstudy_clean$income = factor(
  microstudy_clean$income,
  levels = c(
    "Less than $10,000",
    "$10,000 - $19,999",
    "$20,000 - $29,999",
    "$30,000 - $39,999",
    "$40,000 - $49,999",
    "$50,000 - $59,999",
    "$60,000 - $69,999",
    "$70,000 - $79,999",
    "$80,000 - $89,999",
    "$90,000 - $99,999",
    "$100,000 - $149,999",
    "More than $150,000"
  )
)

ggplot(microstudy_clean, aes(x = income, y = prob_vis, fill = guilty)) +
  geom_point(
    position = position_jitterdodge(
      jitter.width = 0.2,
      jitter.height = 0.4,
      dodge.width = 1
    ),
    size = 0.5
  ) +
  geom_boxplot(position = position_dodge(1),
               alpha = 0.5,
               outlier.shape = NA) +
  ggtitle("Probability Cole Commited the Crime Compared with Income") +
  facet_grid(conclusion.x~.)+
  scale_fill_manual(values = c("grey20", "plum1"), name="Convict?")+
  ylab("Visible Probability")+
  xlab("Income")+
  scale_x_discrete(labels = wrap_format(10))+
  theme_bw()

```

Bases on Figure \@ref(fig:convictsincome), some individuals in the match condition chose to convict across all income levels.
There does not appear to be a clear trend between conviction choice and income.
While two income amounts (\$30,000 - \$39,999 and \$100,000 - \$149,999) consisted of individuals who chose to convict more than they chose not to convict, this trend is not demonstrated in any other income categories.
In the case of the non-match condition, the individuals who did choose to convict came from different income brackets.

```{r}
#| convictsincome,
#| fig.cap= "Income and Conviction Comparison",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE

ggplot(microstudy_clean) +
  geom_bar(aes(x=income, fill=guilty), position = position_dodge(preserve = "single")) +
  ggtitle("") +
  scale_fill_manual(values = c("grey20", "plum1"), name="Convict?")+
  ylab("Count")+
  xlab("Convict?")+
  facet_grid(conclusion.x~.)+
  scale_x_discrete(labels = wrap_format(10))+
  theme_bw()

```

One may expect income to make a difference in how much individuals choose to bet on their opinion in the case, either in the amount of risk an individual is willing to take or in their desire to keep hypothetical money.
This does not appear to be the case, however, based on Figure \@ref(fig:incomebet).
As discussed earlier, many participants in the non-match condition were willing to bet the full amount that the defendant was innocent.
This is reflected across most income categories as well.
In the case of the match condition, we saw earlier that participants were not as extreme in their bets as is seen in the non-match condition.
This trend is also reflected in the boxplots, with a fairly similar distribution of both the innocent and guilty bets across all income categories.

```{r}
#| incomebet,
#| fig.cap= "Income and Betting Comparison",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE

ggplot(microstudy_clean, aes(x = income, y = bet, fill = opinion_guilt)) +
  geom_point(
    position = position_jitterdodge(
      jitter.width = 0.2,
      jitter.height = 0.4,
      dodge.width = 1
    ),
    size = 0.5
  ) +
  geom_boxplot(position = position_dodge(1),
               alpha = 0.5,
               outlier.shape = NA) +
  ggtitle("Amount Bet Compared with Income") +
  facet_grid(conclusion.x~.)+
  scale_fill_manual(values = c("#D81B60","#004D40"), name="Bet Defendant is...", labels=c("Guilty","Innocent"))+
  ylab("Visible Probability")+
  xlab("Income")+
  scale_x_discrete(labels = wrap_format(10))+
  ylim(c(0,50))+
  theme_bw()

```

##### Education

```{r}
#| probeduc,
#| fig.cap= "Education Level and Probability Comparison",
#| fig.width= 10,
#| fig.height= 4,
#| fig.align= "center",
#| echo= FALSE,
#| eval= TRUE,
#| warning= FALSE,
#| message= FALSE

microstudy_clean$educ = factor(
  microstudy_clean$educ,
  levels = c(
    "Less than high school",
    "High school graduate",
    "Some college",
    "2 year degree",
    "4 year degree",
    "Professional degree",
    "Doctorate"
  )
)

ggplot(microstudy_clean, aes(x = educ, y = prob_vis, fill = guilty)) +
  geom_point(
    position = position_jitterdodge(
      jitter.width = 0.2,
      jitter.height = 0.4,
      dodge.width = 1
    ),
    size = 0.5
  ) +
  geom_boxplot(position = position_dodge(1),
               alpha = 0.5,
               outlier.shape = NA) +
  ggtitle("Probability Cole Commited the Crime Compared with Income") +
  facet_grid(conclusion.x~.)+
  scale_fill_manual(values = c("grey20", "plum1"), name="Convict?")+
  ylab("Visible Probability")+
  xlab("Education")+
  scale_x_discrete(labels = wrap_format(10))+
  theme_bw()

```


## Notes


- Reliability: Questions regarding the consistency of the comparison
  - How often to you think the firearms examiner makes mistakes?
     - [blank] out of [blank] bullet comparisons
   - How often to you think the algorithm makes mistakes?
     - [blank] out of [blank] bullet comparisons
   - If other examiners were asked to make the same bullet comparison, how many do you believe would agree with the firearms examiner
     - [blank] out of [blank] examiners would agree with Smith's results of bullet comparison
   - If the algorithm were re-run on the same bullet comparison, how many times do you believe the algorithm would agree with these results?
       - [blank] out of [blank] runs would agree with the results of the bullet comparison
   <!-- - Credibility: Perhaps questions regarding the ability to testify? Or something on credentials, or comparison to another individual -->
   - Scientificity: can directly compare to each other, or have a non-scientific portion to compare to
     - Did you find the algorithm or the bullet comparison to be more scientific?
     - Compared to the case description, how would you rate the scientificity of the bullet comparison
   - How much would you be willing to bet that the crime scene bullet (did/did not) match Cole's gun?
  
- Clarify if the examiner used the algorithm before or after their initial comparison.
 <!-- - If the algorithm is used first, this would potentially be confounding -->
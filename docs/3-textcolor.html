<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>CHAPTER 3 Text analysis with Transcripts | JURY PERCEPTION OF EXPLAINABLE MACHINE LEARNING AND DEMONSTRATIVE EVIDENCE</title>
  <meta name="description" content="CHAPTER 3 Text analysis with Transcripts | JURY PERCEPTION OF EXPLAINABLE MACHINE LEARNING AND DEMONSTRATIVE EVIDENCE" />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="CHAPTER 3 Text analysis with Transcripts | JURY PERCEPTION OF EXPLAINABLE MACHINE LEARNING AND DEMONSTRATIVE EVIDENCE" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="CHAPTER 3 Text analysis with Transcripts | JURY PERCEPTION OF EXPLAINABLE MACHINE LEARNING AND DEMONSTRATIVE EVIDENCE" />
  
  
  

<meta name="author" content="Rachel Edie Sparks Rogers" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="2-study1.html"/>
<link rel="next" href="4-study2.html"/>
<style type="text/css">
p.abstract{
  text-align: center;
  font-weight: bold;
}
div.abstract{
  margin: auto;
  width: 90%;
}
</style>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"></a></li>
<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Literature Review</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#bullet-matching-background"><i class="fa fa-check"></i><b>1.2</b> Bullet Matching Background</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#issues-in-pattern-analysis"><i class="fa fa-check"></i><b>1.3</b> Issues in Pattern Analysis</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="index.html"><a href="index.html#subjectivity-of-comparisons"><i class="fa fa-check"></i><b>1.3.1</b> Subjectivity of Comparisons</a></li>
<li class="chapter" data-level="1.3.2" data-path="index.html"><a href="index.html#scientific-validity"><i class="fa fa-check"></i><b>1.3.2</b> Scientific Validity</a></li>
<li class="chapter" data-level="1.3.3" data-path="index.html"><a href="index.html#scale-of-conclusions"><i class="fa fa-check"></i><b>1.3.3</b> Scale of Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#quantitative-methods"><i class="fa fa-check"></i><b>1.4</b> Quantitative Methods</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="index.html"><a href="index.html#bullet-matching-algorithm"><i class="fa fa-check"></i><b>1.4.1</b> Bullet Matching Algorithm</a></li>
<li class="chapter" data-level="1.4.2" data-path="index.html"><a href="index.html#quantitative-results"><i class="fa fa-check"></i><b>1.4.2</b> Quantitative Results</a></li>
<li class="chapter" data-level="1.4.3" data-path="index.html"><a href="index.html#explainability-in-the-courtroom"><i class="fa fa-check"></i><b>1.4.3</b> Explainability in the Courtroom</a></li>
<li class="chapter" data-level="1.4.4" data-path="index.html"><a href="index.html#demonstrative-evidence"><i class="fa fa-check"></i><b>1.4.4</b> Demonstrative Evidence</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#conclusion"><i class="fa fa-check"></i><b>1.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-study1.html"><a href="2-study1.html"><i class="fa fa-check"></i><b>2</b> Jury Perception of Bullet Matching Algorithms and Demostrative Evidence</a>
<ul>
<li class="chapter" data-level="2.1" data-path="2-study1.html"><a href="2-study1.html#background"><i class="fa fa-check"></i><b>2.1</b> Background</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="2-study1.html"><a href="2-study1.html#firearms-examiners"><i class="fa fa-check"></i><b>2.1.1</b> Firearms Examiners</a></li>
<li class="chapter" data-level="2.1.2" data-path="2-study1.html"><a href="2-study1.html#bullet-matching-algorithm-1"><i class="fa fa-check"></i><b>2.1.2</b> Bullet Matching Algorithm</a></li>
<li class="chapter" data-level="2.1.3" data-path="2-study1.html"><a href="2-study1.html#explainable-machine-learning---previous-research"><i class="fa fa-check"></i><b>2.1.3</b> Explainable Machine Learning - Previous Research</a></li>
<li class="chapter" data-level="2.1.4" data-path="2-study1.html"><a href="2-study1.html#demonstrative-evidence-1"><i class="fa fa-check"></i><b>2.1.4</b> Demonstrative Evidence</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2-study1.html"><a href="2-study1.html#methods"><i class="fa fa-check"></i><b>2.2</b> Methods</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="2-study1.html"><a href="2-study1.html#study-format"><i class="fa fa-check"></i><b>2.2.1</b> Study Format</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-study1.html"><a href="2-study1.html#prolific"><i class="fa fa-check"></i><b>2.2.2</b> Prolific</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-study1.html"><a href="2-study1.html#results"><i class="fa fa-check"></i><b>2.3</b> Results</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="2-study1.html"><a href="2-study1.html#participants"><i class="fa fa-check"></i><b>2.3.1</b> Participants</a></li>
<li class="chapter" data-level="2.3.2" data-path="2-study1.html"><a href="2-study1.html#overview"><i class="fa fa-check"></i><b>2.3.2</b> Overview</a></li>
<li class="chapter" data-level="2.3.3" data-path="2-study1.html"><a href="2-study1.html#probability"><i class="fa fa-check"></i><b>2.3.3</b> Probability</a></li>
<li class="chapter" data-level="2.3.4" data-path="2-study1.html"><a href="2-study1.html#credibility"><i class="fa fa-check"></i><b>2.3.4</b> Credibility</a></li>
<li class="chapter" data-level="2.3.5" data-path="2-study1.html"><a href="2-study1.html#reliability"><i class="fa fa-check"></i><b>2.3.5</b> Reliability</a></li>
<li class="chapter" data-level="2.3.6" data-path="2-study1.html"><a href="2-study1.html#scientificity"><i class="fa fa-check"></i><b>2.3.6</b> Scientificity</a></li>
<li class="chapter" data-level="2.3.7" data-path="2-study1.html"><a href="2-study1.html#understanding"><i class="fa fa-check"></i><b>2.3.7</b> Understanding</a></li>
<li class="chapter" data-level="2.3.8" data-path="2-study1.html"><a href="2-study1.html#uniqueness"><i class="fa fa-check"></i><b>2.3.8</b> Uniqueness</a></li>
<li class="chapter" data-level="2.3.9" data-path="2-study1.html"><a href="2-study1.html#strength"><i class="fa fa-check"></i><b>2.3.9</b> Strength</a></li>
<li class="chapter" data-level="2.3.10" data-path="2-study1.html"><a href="2-study1.html#mistakes"><i class="fa fa-check"></i><b>2.3.10</b> Mistakes</a></li>
<li class="chapter" data-level="2.3.11" data-path="2-study1.html"><a href="2-study1.html#comparing-algorithm-values-to-examiner-values"><i class="fa fa-check"></i><b>2.3.11</b> Comparing Algorithm Values to Examiner Values</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-study1.html"><a href="2-study1.html#discussion"><i class="fa fa-check"></i><b>2.4</b> Discussion</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="2-study1.html"><a href="2-study1.html#summary-of-results"><i class="fa fa-check"></i><b>2.4.1</b> Summary of Results</a></li>
<li class="chapter" data-level="2.4.2" data-path="2-study1.html"><a href="2-study1.html#limitations"><i class="fa fa-check"></i><b>2.4.2</b> Limitations</a></li>
<li class="chapter" data-level="2.4.3" data-path="2-study1.html"><a href="2-study1.html#future-research"><i class="fa fa-check"></i><b>2.4.3</b> Future Research</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-textcolor.html"><a href="3-textcolor.html"><i class="fa fa-check"></i><b>3</b> Text analysis with Transcripts</a>
<ul>
<li class="chapter" data-level="3.1" data-path="3-textcolor.html"><a href="3-textcolor.html#introduction-1"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="3-textcolor.html"><a href="3-textcolor.html#background-1"><i class="fa fa-check"></i><b>3.2</b> Background</a></li>
<li class="chapter" data-level="3.3" data-path="3-textcolor.html"><a href="3-textcolor.html#methods-1"><i class="fa fa-check"></i><b>3.3</b> Methods</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="3-textcolor.html"><a href="3-textcolor.html#data-cleaning"><i class="fa fa-check"></i><b>3.3.1</b> Data Cleaning</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-textcolor.html"><a href="3-textcolor.html#notes"><i class="fa fa-check"></i><b>3.4</b> Notes</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-study2.html"><a href="4-study2.html"><i class="fa fa-check"></i><b>4</b> Jury Perception Revisited: This Time with Caricatures</a></li>
<li class="chapter" data-level="" data-path="conclusion-1.html"><a href="conclusion-1.html"><i class="fa fa-check"></i>Conclusion</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-testimony-transcripts.html"><a href="A-testimony-transcripts.html"><i class="fa fa-check"></i><b>A</b> Testimony Transcripts</a>
<ul>
<li class="chapter" data-level="A.1" data-path="A-testimony-transcripts.html"><a href="A-testimony-transcripts.html#firearm-examiner"><i class="fa fa-check"></i><b>A.1</b> Firearm Examiner</a></li>
<li class="chapter" data-level="A.2" data-path="A-testimony-transcripts.html"><a href="A-testimony-transcripts.html#algorithm-expert"><i class="fa fa-check"></i><b>A.2</b> Algorithm Expert</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="B-study-2-changes.html"><a href="B-study-2-changes.html"><i class="fa fa-check"></i><b>B</b> Study 2 Changes</a>
<ul>
<li class="chapter" data-level="B.1" data-path="B-study-2-changes.html"><a href="B-study-2-changes.html#cautions-against-expert-witnesses"><i class="fa fa-check"></i><b>B.1</b> Cautions Against Expert Witnesses</a>
<ul>
<li class="chapter" data-level="B.1.1" data-path="B-study-2-changes.html"><a href="B-study-2-changes.html#jury-instructions"><i class="fa fa-check"></i><b>B.1.1</b> Jury Instructions</a></li>
<li class="chapter" data-level="B.1.2" data-path="B-study-2-changes.html"><a href="B-study-2-changes.html#opinion-witness"><i class="fa fa-check"></i><b>B.1.2</b> Opinion Witness</a></li>
<li class="chapter" data-level="B.1.3" data-path="B-study-2-changes.html"><a href="B-study-2-changes.html#cross-examination"><i class="fa fa-check"></i><b>B.1.3</b> Cross Examination</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="B-study-2-changes.html"><a href="B-study-2-changes.html#clarifying-sides"><i class="fa fa-check"></i><b>B.2</b> Clarifying Sides</a></li>
<li class="chapter" data-level="B.3" data-path="B-study-2-changes.html"><a href="B-study-2-changes.html#images"><i class="fa fa-check"></i><b>B.3</b> Images</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="colophon.html"><a href="colophon.html"><i class="fa fa-check"></i>Colophon</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">JURY PERCEPTION OF EXPLAINABLE MACHINE LEARNING AND DEMONSTRATIVE EVIDENCE</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="textcolor" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">CHAPTER 3</span> Text analysis with Transcripts<a href="3-textcolor.html#textcolor" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="introduction-1" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Introduction<a href="3-textcolor.html#introduction-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When conducting studies that rely on participants reading a longer document, researchers may be interested in determining what portions of the document participants find worth noting.
This could provide useful information about areas of interest by creating a type of heat map for the document.
When the study document consists of multiple pages and notes are recorded sequentially, the problem then becomes twofold: first the participants’ notes must be cleaned so that the recorded text corresponds to the current page, then a method must be developed to match the frequency of the participants’ notes to the study document.</p>
<p>In order to clean the notes, two different methods are considered and then combined: the First n Character method and the Longest Common Substring method.
The First n Character method relies on the concept of edit distance for matching and removing previous notes from sequential study documents.
This method was developed specifically for this document comparison.
The Longest Common Substring method, on the other hand, searches for common text between two sequential pages to be removed.
After the notes are cleaned, sequences of 5 words (collocations) are used to find areas of the testimony that participants focus on.
For indirect matches, such as typos, weights are applied to these fuzzy matches to contribute to the total count.</p>
<p>This method was applied to notes taken from a recent study.
Dr. Vanderplas and I conducted a study on jury perception, in which participants were asked to read over a testimony transcript and answer some questions related to the scenarios.
Participants were supplied with a notepad in order to take notes throughout the testimony.
We are interested in comparing this notepad to the given testimony, in order to determine which portions of the testimony the participants found to be worth recording the most.
Portions of the testimony that bear the most similarity to the collective notes will be more highlighted than testimony that appears less frequently in the collective notes.
The method outlined above resulted in scenario testimonies that indicate where participants copied notes.</p>
</div>
<div id="background-1" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Background<a href="3-textcolor.html#background-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>For data cleaning, a previous page’s notes are matched to the next page’s notes in order to remove duplicate text.
This can be thought of as a form of pattern matching.
There are plenty of examples of pattern matching in text analysis - such as Baeza-Yates and Gonnet, and Landau and Vishkin.
These papers rely on a set pattern to be found in the reference text, with a defined number of differences allowed between the pattern and the text.
According th Baeza-Yates and Gonnet, many algorithmic methods have been developed to solve this problem, with allowances for mismatches between the reference text and the pattern.
A similar allowance for differences is present in Landau and Vishkin, where differences are defined as either insertions, deletions, or substitutions.
This definition of differences is the same definition that is used in computing Levenshtein distance, also known as edit distance (Levenshtein).
Levenshtein considered the issue of insertions, deletions, and substitutions with binary code.
This concept has later been extended to include more extensive strings, as demonstrated by Konstantinidis.
The edit distance can be used to determine the extent of matching text when comparing two sequential note sheets, in order to identify if a portion of notes should be removed.</p>
<p>One thing that differentiates this problem from other text analysis methods is that there is no set in stone pattern - while the analysis is based on the previous page of notes, individuals do not always keep the previous page of notes the same - some delete parts, and some add new information in the middle.
Thus, the goal is to not only find and remove only exact matches of the entire previous note sheet, but to also remove previous notes - whether they be shorter or discontinuous.
While evaluating edit distance is useful when finding direct matches, the Longest Common Substring (LCS) method can be used to find pieces of notes that match between pages, so that this repeated text can be removed.</p>
<p>Landau and Vishkin’s discussion of pattern matching with k differences includes both a dynamic programming approach, as well as the construction of suffix trees.
These methods correspond to those proposed for finding the Longest Common Substring between two sequences.
This problem has been used to compare biological sequences (Crochemore et al.).
An early solution for finding the longest common substring involves the construction of a suffix tree (Charalampopoulos et al.).
The suffix tree method is described by Gusfield; in short, each unique suffix of a string would contribute a new branch to the suffix tree, where leafs consist of the string’s terminal character: $ is used avoid recurrence with previous characters in the string.
While I have located a package on Github that utilizes the suffix tree for LCS (Lang), I have been unable to successfully download the package.
Another solution implemented by Bielow et al. in a CRAN R package uses dynamic programming, which involves the construction of a matrix that records the length of a matching string at character <span class="math inline">\(i\)</span> for string 1 (in the <span class="math inline">\(i\)</span>th row), and character <span class="math inline">\(j\)</span> for string 2 (in the <span class="math inline">\(j\)</span>th column).
Because the dynamic programming method has an R implementation, it is utilized for this analysis.
The comparison between suffix tree and dynamic programming methods will be evaluated in a future analysis.</p>
<p>Once the participants’ notes are cleaned, they must be compared to the study transcript.
In the realm of non-fixed pattern matching, there are plagiarism recognition methods (such as TurnItIn).
In these cases, a portion of a student’s text is cross referenced with published or online references, in order to determine if the text was copied.
Because this type of correspondence is on a larger level than individual words, collocation analysis is used.
While collocations traditionally refer to words that occur more frequently together - such as “white house”(Merriam-Webster), tools for collocation analysis helpfully provide the frequency of occurrence for strings of a specified length (Schweinberger).
In a reference to algorithmic detection of plagiarism in computer programs, Parker and Hamblen describe an algorithm that uses the character differences in order to compare how similar programs are.
Other algorithms they discuss use code-specific features such as number of operators, lines of comments, and number of various loop statements.
Because we are only concerned with the content of the notes, there is little information to be gained from formatting, as there is in plagiarism detection in programs.
However, character differences can effectively be used to indicate similarity between participants’ notes and the study testimony.
This is useful in situation where individuals do not copy the notes directly.
In these cases, fuzzy matching can be used to find the testimony collocation that is the most similar to the participants’ written notes.
This approximate string matching allows for matching strings that do not correspond directly (Gusfield), which would allow for matching up participants’ inexact notes with the closest testimony collocation.</p>
</div>
<div id="methods-1" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Methods<a href="3-textcolor.html#methods-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="data-cleaning" class="section level3 hasAnchor" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Data Cleaning<a href="3-textcolor.html#data-cleaning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Table <a href="#tab:noteexample"><strong>??</strong></a> is an example of what sequential notes may look like, taken from the second and third pages of a study participant’s notes.
Because participants are provided with the same continuous notepad throughout the study, the database records each page as a “screenshot” of what is written on their notes when they advance to the next page - this provides cumulative notes.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="3-textcolor.html#cb2-1" aria-hidden="true" tabindex="-1"></a>comments <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;data/clean_notes.csv&quot;</span>)</span>
<span id="cb2-2"><a href="3-textcolor.html#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># length(unique(subset(comments, notes !=</span></span>
<span id="cb2-3"><a href="3-textcolor.html#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># &#39;&#39;)$clean_prints)) val_prints &lt;-</span></span>
<span id="cb2-4"><a href="3-textcolor.html#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># sample(unique(subset(comments, notes !=</span></span>
<span id="cb2-5"><a href="3-textcolor.html#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># &#39;&#39;)$clean_prints), size=30, replace=FALSE)</span></span>
<span id="cb2-6"><a href="3-textcolor.html#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># val_prints &lt;- c(val_prints, 503, 359, 39,</span></span>
<span id="cb2-7"><a href="3-textcolor.html#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 368, 547) val_dataset &lt;- comments %&gt;%</span></span>
<span id="cb2-8"><a href="3-textcolor.html#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># subset(clean_prints %in% val_prints)</span></span>
<span id="cb2-9"><a href="3-textcolor.html#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># write.csv(val_dataset,</span></span>
<span id="cb2-10"><a href="3-textcolor.html#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># &#39;validation_dataset.csv&#39;) dim(val_dataset)</span></span>
<span id="cb2-11"><a href="3-textcolor.html#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="3-textcolor.html#cb2-12" aria-hidden="true" tabindex="-1"></a>test_comments <span class="ot">&lt;-</span> comments[<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, ]</span>
<span id="cb2-13"><a href="3-textcolor.html#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="3-textcolor.html#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="fu">kable</span>(test_comments <span class="sc">%&gt;%</span></span>
<span id="cb2-15"><a href="3-textcolor.html#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(page_count <span class="sc">==</span> <span class="dv">2</span> <span class="sc">|</span> page_count <span class="sc">==</span> <span class="dv">3</span>) <span class="sc">%&gt;%</span></span>
<span id="cb2-16"><a href="3-textcolor.html#cb2-16" aria-hidden="true" tabindex="-1"></a>    dplyr<span class="sc">::</span><span class="fu">select</span>(page_count, notes), <span class="at">caption =</span> <span class="st">&quot;Participant Note Example&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb2-17"><a href="3-textcolor.html#cb2-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">column_spec</span>(<span class="dv">2</span>, <span class="at">width =</span> <span class="st">&quot;30em&quot;</span>)</span></code></pre></div>
<table>
<caption>
<span id="tab:unnamed-chunk-35">Table 3.1: </span>Participant Note Example
</caption>
<thead>
<tr>
<th style="text-align:right;">
page_count
</th>
<th style="text-align:left;">
notes
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;width: 30em; ">
Richard Cole - has been charged with willfully discharging a firearm in a place of business. This crime is a felony.
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:left;width: 30em; ">
<p>Richard Cole - has been charged with willfully discharging a firearm in a place of business. This crime is a felony.</p>
police officer pulled over Richard Cole for speeding. During a search of the Defendant’s vehicle, the detective located a 9mm handgun, which was legally licensed to the Defendant.
</td>
</tr>
</tbody>
</table>
<p>In order to appropriately clean the notes, the duplicated text (“Richard Cole - has been charted with willfully discharging a firearm in a place of business. This crime is a felony.”) needs to be removed from the third page, to leave only notes that correspond to the third page’s testimony.</p>
<div id="first-n-character-fnc-method" class="section level4 hasAnchor" number="3.3.1.1">
<h4><span class="header-section-number">3.3.1.1</span> First n Character (FNC) Method<a href="3-textcolor.html#first-n-character-fnc-method" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In scenarios such as the table above, a straightforward method for note cleaning would be to measure the length of the previous page’s notes (n), and compare the previous notes to the first n characters in the current pages notes via edit distance.
The edit distance is the number of characters that would need to be changed in order to transform the first string into the second string.
This includes insertions, deletions, and substitutions(in the case of the “adist” function from the R Core Team).
For example, “Hat” and “Hot” would have an edit distance of 1, because the strings match if the “a” is turned into an “o”.
Similarly, “Over there” and “there” would have an edit distance of 5, since 5 characters are deleted (the letters in “Over” plus an additional space).
If the edit distance is small (indicating a correspondence to the previous page’s notes), the first n characters can be removed.
If we consider the table is above, it is clear to see how this method can be applied.
The page 2 notes perfectly line up with the first two lines in the page 3 notes, resulting in an edit distance of 0 when comparing the first n characters of the third page.
Thus, by removing this beginning section, we would be left with the notes that are unique to page 3 - namely, the last two lines.</p>
<p>This method works well when participants take notes sequentially.
In some instances, however, participants will delete portions of their previous notes, add new notes either before or in the middle of their old notes, or duplicate their old notes.
When participants delete a portion of their notes or add new notes before/in the middle of their old notes, the edit distance between the old and new notes could be large.
The first n character method would not be able to appropriately clean these notes.</p>
</div>
<div id="longest-common-substring-lcs-method" class="section level4 hasAnchor" number="3.3.1.2">
<h4><span class="header-section-number">3.3.1.2</span> Longest Common Substring (LCS) Method<a href="3-textcolor.html#longest-common-substring-lcs-method" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Another method for matching text between two different sets of notes is the Longest Common Substring (LCS).
This method searches two strings for the longest sequence of sequential characters that they have in common, which is then returned.
For example, in Figure <a href="3-textcolor.html#fig:lcs">3.1</a>, the LCS between the two strings is “the cat enjoys napping”.
In the process of note cleaning, this would be the string that is removed from the second page of notes, resulting in “When it is quiet” as the cleaned (non-repeated) notes.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:lcs"></span>
<img src="images/svg_graph.png" alt="Longest Common Substring Diagram" width="\linewidth" />
<p class="caption">
Figure 3.1: Longest Common Substring Diagram
</p>
</div>
</div>
</div>
</div>
<div id="notes" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Notes<a href="3-textcolor.html#notes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><p>Participants of the first study were allowed to take notes while reading through the transcripts, which are saved by page number</p></li>
<li><p>We would like to use this to highlight which parts of the testimonies the participants found to be important</p></li>
<li><p>First attempt:</p>
<ul>
<li>ggplot: allows for both a gradient and transparency to be added to words based on their frequency</li>
<li>graphing words of the transcript resulted in uneven spacing</li>
<li>Relative frequency was computed based on the number of times the word appeared on the page</li>
</ul></li>
<li><p>Second attempt:</p>
<ul>
<li>Using CSS instead of ggplot: can set gradient through color outputted by ggplot</li>
<li>Words can be equally spaced
<!-- - Currently assigning a new color to each word - this is not efficient -->
<!-- - Now in CSS for tab format --></li>
<li>Labels added with gradient scale</li>
<li>Change from relative frequency of individual words to average collocation frequency per word (with collocations of length 5)
-Include fuzzy matching for indirect matches (typos/skipped words)</li>
</ul></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="2-study1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="4-study2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": [["thesis.pdf", "PDF"], ["thesis.epub", "EPUB"], ["thesis.docx", "Word"]],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"style": "style.css"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

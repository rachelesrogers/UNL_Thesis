<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>JURY PERCEPTION OF EXPLAINABLE MACHINE LEARNING AND DEMONSTRATIVE EVIDENCE</title>
  <meta name="description" content="JURY PERCEPTION OF EXPLAINABLE MACHINE LEARNING AND DEMONSTRATIVE EVIDENCE" />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="JURY PERCEPTION OF EXPLAINABLE MACHINE LEARNING AND DEMONSTRATIVE EVIDENCE" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="JURY PERCEPTION OF EXPLAINABLE MACHINE LEARNING AND DEMONSTRATIVE EVIDENCE" />
  
  
  

<meta name="author" content="Rachel Edie Sparks Rogers" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  

<link rel="next" href="2-study1.html"/>
<style type="text/css">
p.abstract{
  text-align: center;
  font-weight: bold;
}
div.abstract{
  margin: auto;
  width: 90%;
}
</style>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"></a></li>
<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Literature Review</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#bullet-matching-background"><i class="fa fa-check"></i><b>1.2</b> Bullet Matching Background</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#issues-in-pattern-analysis"><i class="fa fa-check"></i><b>1.3</b> Issues in Pattern Analysis</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="index.html"><a href="index.html#subjectivity-of-comparisons"><i class="fa fa-check"></i><b>1.3.1</b> Subjectivity of Comparisons</a></li>
<li class="chapter" data-level="1.3.2" data-path="index.html"><a href="index.html#scientific-validity"><i class="fa fa-check"></i><b>1.3.2</b> Scientific Validity</a></li>
<li class="chapter" data-level="1.3.3" data-path="index.html"><a href="index.html#language-in-the-courtroom"><i class="fa fa-check"></i><b>1.3.3</b> Language in the Courtroom</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#quantitative-methods"><i class="fa fa-check"></i><b>1.4</b> Quantitative Methods</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="index.html"><a href="index.html#bullet-matching-algorithm"><i class="fa fa-check"></i><b>1.4.1</b> Bullet Matching Algorithm</a></li>
<li class="chapter" data-level="1.4.2" data-path="index.html"><a href="index.html#reporting-quantitative-results"><i class="fa fa-check"></i><b>1.4.2</b> Reporting Quantitative Results</a></li>
<li class="chapter" data-level="1.4.3" data-path="index.html"><a href="index.html#explainability-in-the-courtroom"><i class="fa fa-check"></i><b>1.4.3</b> Explainability in the Courtroom</a></li>
<li class="chapter" data-level="1.4.4" data-path="index.html"><a href="index.html#demonstrative-evidence"><i class="fa fa-check"></i><b>1.4.4</b> Demonstrative Evidence</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#response-methods"><i class="fa fa-check"></i><b>1.5</b> Response Methods</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#conclusion"><i class="fa fa-check"></i><b>1.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-study1.html"><a href="2-study1.html"><i class="fa fa-check"></i><b>2</b> Jury Perception of Bullet Matching Algorithms and Demostrative Evidence</a>
<ul>
<li class="chapter" data-level="2.1" data-path="2-study1.html"><a href="2-study1.html#background"><i class="fa fa-check"></i><b>2.1</b> Background</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="2-study1.html"><a href="2-study1.html#firearms-examiners"><i class="fa fa-check"></i><b>2.1.1</b> Firearms Examiners</a></li>
<li class="chapter" data-level="2.1.2" data-path="2-study1.html"><a href="2-study1.html#bullet-matching-algorithm-1"><i class="fa fa-check"></i><b>2.1.2</b> Bullet Matching Algorithm</a></li>
<li class="chapter" data-level="2.1.3" data-path="2-study1.html"><a href="2-study1.html#explainable-machine-learning---previous-research"><i class="fa fa-check"></i><b>2.1.3</b> Explainable Machine Learning - Previous Research</a></li>
<li class="chapter" data-level="2.1.4" data-path="2-study1.html"><a href="2-study1.html#demonstrative-evidence-1"><i class="fa fa-check"></i><b>2.1.4</b> Demonstrative Evidence</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2-study1.html"><a href="2-study1.html#methods"><i class="fa fa-check"></i><b>2.2</b> Methods</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="2-study1.html"><a href="2-study1.html#study-format"><i class="fa fa-check"></i><b>2.2.1</b> Study Format</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-study1.html"><a href="2-study1.html#prolific"><i class="fa fa-check"></i><b>2.2.2</b> Prolific</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-study1.html"><a href="2-study1.html#results"><i class="fa fa-check"></i><b>2.3</b> Results</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="2-study1.html"><a href="2-study1.html#participants"><i class="fa fa-check"></i><b>2.3.1</b> Participants</a></li>
<li class="chapter" data-level="2.3.2" data-path="2-study1.html"><a href="2-study1.html#overview"><i class="fa fa-check"></i><b>2.3.2</b> Overview</a></li>
<li class="chapter" data-level="2.3.3" data-path="2-study1.html"><a href="2-study1.html#probability"><i class="fa fa-check"></i><b>2.3.3</b> Probability</a></li>
<li class="chapter" data-level="2.3.4" data-path="2-study1.html"><a href="2-study1.html#credibility"><i class="fa fa-check"></i><b>2.3.4</b> Credibility</a></li>
<li class="chapter" data-level="2.3.5" data-path="2-study1.html"><a href="2-study1.html#reliability"><i class="fa fa-check"></i><b>2.3.5</b> Reliability</a></li>
<li class="chapter" data-level="2.3.6" data-path="2-study1.html"><a href="2-study1.html#scientificity"><i class="fa fa-check"></i><b>2.3.6</b> Scientificity</a></li>
<li class="chapter" data-level="2.3.7" data-path="2-study1.html"><a href="2-study1.html#understanding"><i class="fa fa-check"></i><b>2.3.7</b> Understanding</a></li>
<li class="chapter" data-level="2.3.8" data-path="2-study1.html"><a href="2-study1.html#uniqueness"><i class="fa fa-check"></i><b>2.3.8</b> Uniqueness</a></li>
<li class="chapter" data-level="2.3.9" data-path="2-study1.html"><a href="2-study1.html#strength"><i class="fa fa-check"></i><b>2.3.9</b> Strength</a></li>
<li class="chapter" data-level="2.3.10" data-path="2-study1.html"><a href="2-study1.html#mistakes"><i class="fa fa-check"></i><b>2.3.10</b> Mistakes</a></li>
<li class="chapter" data-level="2.3.11" data-path="2-study1.html"><a href="2-study1.html#comparing-algorithm-values-to-examiner-values"><i class="fa fa-check"></i><b>2.3.11</b> Comparing Algorithm Values to Examiner Values</a></li>
<li class="chapter" data-level="2.3.12" data-path="2-study1.html"><a href="2-study1.html#comments"><i class="fa fa-check"></i><b>2.3.12</b> Comments</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-study1.html"><a href="2-study1.html#discussion"><i class="fa fa-check"></i><b>2.4</b> Discussion</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="2-study1.html"><a href="2-study1.html#summary-of-results"><i class="fa fa-check"></i><b>2.4.1</b> Summary of Results</a></li>
<li class="chapter" data-level="2.4.2" data-path="2-study1.html"><a href="2-study1.html#limitations"><i class="fa fa-check"></i><b>2.4.2</b> Limitations</a></li>
<li class="chapter" data-level="2.4.3" data-path="2-study1.html"><a href="2-study1.html#future-research"><i class="fa fa-check"></i><b>2.4.3</b> Future Research</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-textcolor.html"><a href="3-textcolor.html"><i class="fa fa-check"></i><b>3</b> Text analysis with Transcripts</a>
<ul>
<li class="chapter" data-level="3.1" data-path="3-textcolor.html"><a href="3-textcolor.html#introduction-1"><i class="fa fa-check"></i><b>3.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="3-textcolor.html"><a href="3-textcolor.html#literature-review"><i class="fa fa-check"></i><b>3.1.1</b> Literature Review</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3-textcolor.html"><a href="3-textcolor.html#implementation"><i class="fa fa-check"></i><b>3.2</b> Implementation</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="3-textcolor.html"><a href="3-textcolor.html#data-cleaning"><i class="fa fa-check"></i><b>3.2.1</b> Data Cleaning</a></li>
<li class="chapter" data-level="3.2.2" data-path="3-textcolor.html"><a href="3-textcolor.html#note-analysis"><i class="fa fa-check"></i><b>3.2.2</b> Note Analysis</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3-textcolor.html"><a href="3-textcolor.html#case-study"><i class="fa fa-check"></i><b>3.3</b> Case Study</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="3-textcolor.html"><a href="3-textcolor.html#the-data"><i class="fa fa-check"></i><b>3.3.1</b> The Data</a></li>
<li class="chapter" data-level="3.3.2" data-path="3-textcolor.html"><a href="3-textcolor.html#data-cleaning-1"><i class="fa fa-check"></i><b>3.3.2</b> Data Cleaning</a></li>
<li class="chapter" data-level="3.3.3" data-path="3-textcolor.html"><a href="3-textcolor.html#collocation-analysis"><i class="fa fa-check"></i><b>3.3.3</b> Collocation Analysis</a></li>
<li class="chapter" data-level="3.3.4" data-path="3-textcolor.html"><a href="3-textcolor.html#final-output"><i class="fa fa-check"></i><b>3.3.4</b> Final Output</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-textcolor.html"><a href="3-textcolor.html#discussion-1"><i class="fa fa-check"></i><b>3.4</b> Discussion</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="3-textcolor.html"><a href="3-textcolor.html#conclusion-1"><i class="fa fa-check"></i><b>3.4.1</b> Conclusion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-study2.html"><a href="4-study2.html"><i class="fa fa-check"></i><b>4</b> An Investigation of Response Types</a>
<ul>
<li class="chapter" data-level="4.1" data-path="4-study2.html"><a href="4-study2.html#background-1"><i class="fa fa-check"></i><b>4.1</b> Background</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="4-study2.html"><a href="4-study2.html#problems-in-study-1"><i class="fa fa-check"></i><b>4.1.1</b> Problems in Study 1</a></li>
<li class="chapter" data-level="4.1.2" data-path="4-study2.html"><a href="4-study2.html#study-visualization"><i class="fa fa-check"></i><b>4.1.2</b> Study Visualization</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="4-study2.html"><a href="4-study2.html#methods-1"><i class="fa fa-check"></i><b>4.2</b> Methods</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="4-study2.html"><a href="4-study2.html#study-format-1"><i class="fa fa-check"></i><b>4.2.1</b> Study Format</a></li>
<li class="chapter" data-level="4.2.2" data-path="4-study2.html"><a href="4-study2.html#prolific-1"><i class="fa fa-check"></i><b>4.2.2</b> Prolific</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4-study2.html"><a href="4-study2.html#results-1"><i class="fa fa-check"></i><b>4.3</b> Results</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="4-study2.html"><a href="4-study2.html#participants-1"><i class="fa fa-check"></i><b>4.3.1</b> Participants</a></li>
<li class="chapter" data-level="4.3.2" data-path="4-study2.html"><a href="4-study2.html#questions-from-study-1"><i class="fa fa-check"></i><b>4.3.2</b> Questions from Study 1</a></li>
<li class="chapter" data-level="4.3.3" data-path="4-study2.html"><a href="4-study2.html#new-study-questions"><i class="fa fa-check"></i><b>4.3.3</b> New Study Questions</a></li>
<li class="chapter" data-level="4.3.4" data-path="4-study2.html"><a href="4-study2.html#scale-comparison"><i class="fa fa-check"></i><b>4.3.4</b> Scale Comparison</a></li>
<li class="chapter" data-level="4.3.5" data-path="4-study2.html"><a href="4-study2.html#demographic-comparison"><i class="fa fa-check"></i><b>4.3.5</b> Demographic Comparison</a></li>
<li class="chapter" data-level="4.3.6" data-path="4-study2.html"><a href="4-study2.html#notepad-analysis"><i class="fa fa-check"></i><b>4.3.6</b> Notepad Analysis</a></li>
<li class="chapter" data-level="4.3.7" data-path="4-study2.html"><a href="4-study2.html#participant-comments"><i class="fa fa-check"></i><b>4.3.7</b> Participant Comments</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="4-study2.html"><a href="4-study2.html#conclusion-2"><i class="fa fa-check"></i><b>4.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-finalstudy.html"><a href="5-finalstudy.html"><i class="fa fa-check"></i><b>5</b> Conclusion</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-testimony-transcripts.html"><a href="A-testimony-transcripts.html"><i class="fa fa-check"></i><b>A</b> Testimony Transcripts</a>
<ul>
<li class="chapter" data-level="A.1" data-path="A-testimony-transcripts.html"><a href="A-testimony-transcripts.html#firearm-examiner"><i class="fa fa-check"></i><b>A.1</b> Firearm Examiner</a></li>
<li class="chapter" data-level="A.2" data-path="A-testimony-transcripts.html"><a href="A-testimony-transcripts.html#algorithm-expert"><i class="fa fa-check"></i><b>A.2</b> Algorithm Expert</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="B-study-2-changes.html"><a href="B-study-2-changes.html"><i class="fa fa-check"></i><b>B</b> Study 2 Changes</a>
<ul>
<li class="chapter" data-level="B.1" data-path="B-study-2-changes.html"><a href="B-study-2-changes.html#cautions-against-expert-witnesses"><i class="fa fa-check"></i><b>B.1</b> Cautions Against Expert Witnesses</a>
<ul>
<li class="chapter" data-level="B.1.1" data-path="B-study-2-changes.html"><a href="B-study-2-changes.html#jury-instructions"><i class="fa fa-check"></i><b>B.1.1</b> Jury Instructions</a></li>
<li class="chapter" data-level="B.1.2" data-path="B-study-2-changes.html"><a href="B-study-2-changes.html#opinion-witness"><i class="fa fa-check"></i><b>B.1.2</b> Opinion Witness</a></li>
<li class="chapter" data-level="B.1.3" data-path="B-study-2-changes.html"><a href="B-study-2-changes.html#cross-examination"><i class="fa fa-check"></i><b>B.1.3</b> Cross Examination</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="B-study-2-changes.html"><a href="B-study-2-changes.html#clarifying-sides"><i class="fa fa-check"></i><b>B.2</b> Clarifying Sides</a></li>
<li class="chapter" data-level="B.3" data-path="B-study-2-changes.html"><a href="B-study-2-changes.html#images"><i class="fa fa-check"></i><b>B.3</b> Images</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="C-select-comments.html"><a href="C-select-comments.html"><i class="fa fa-check"></i><b>C</b> Select Comments</a>
<ul>
<li class="chapter" data-level="C.1" data-path="C-select-comments.html"><a href="C-select-comments.html#initial-study"><i class="fa fa-check"></i><b>C.1</b> Initial Study</a></li>
<li class="chapter" data-level="C.2" data-path="C-select-comments.html"><a href="C-select-comments.html#response-type-survey"><i class="fa fa-check"></i><b>C.2</b> Response Type Survey</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="colophon.html"><a href="colophon.html"><i class="fa fa-check"></i>Colophon</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">JURY PERCEPTION OF EXPLAINABLE MACHINE LEARNING AND DEMONSTRATIVE EVIDENCE</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">JURY PERCEPTION OF EXPLAINABLE MACHINE LEARNING AND DEMONSTRATIVE EVIDENCE</h1>
<p class="author"><em>Rachel Edie Sparks Rogers</em></p>
<div class="abstract">
<p class="abstract">Abstract</p>
<p>Subjective pattern comparison has been subject to increased scrutiny by the courts and by the general public, resulting in an increased interest in pattern comparison algorithms that provide quantitative assessments of similarity for use by forensic scientists. While these algorithms would mark an improvement over current subjective comparison methods, individuals without a statistical background may struggle with the statistical concepts and language necessary for describing algorithmic methods. If algorithms are to be used, examiners must be able to testify about their use in a way that is accessible to the jury. In a series of studies, we conduct an assessment of language and supporting visual aids which might be used to explain bullet matching algorithms. In the initial study, we encountered a response type calibration issue - individuals thought highly of the forensic witness and evidence regardless of experimental conditions, ‘maxing out’ Likert response scales and leaving us unable to tell if the conditions had any effect. While this study indicated that individuals overall found the testimony to be reliable, credible, and scientific, it did not readily provide information about our question of interest. Additional data from this study was found in the participants’ note pads.Through cleaning sequential notes and designing a method for highlighting study transcripts according to the frequency of collocations in participant notes, we can determining which portions of testimony participants found ‘noteworthy’.We also conducted a study on response types to determine the consistency of participant responses across response types, compare a variety of response types, and determine which response type may be appropriately calibrated for addressing the initial research question of jury perception of algorithms and demonstrative evidence. The response types used in this investigation include the participant’s interpretation of the strength of evidence (Likert scale), conviction decision (binary), opinion of guilt (binary), willingness to bet on their opinion of guilt (numeric), probability of guilt (numeric), and chance of guilt/innocence (numeric or multiple choice). The note cleaning, text analysis, and testimony tools we developed throughout this series of experiments will benefit our future research in jury perception, as well as future transcript studies.</p>
</div>
</div>
<div id="litreview" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">CHAPTER 1</span> Literature Review<a href="index.html#litreview" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="introduction" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> Introduction<a href="index.html#introduction" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are many forms of forensic evidence that have been generally accepted unique and identifying (without proof).
There are even some methods - such as bite mark analysis - that have been used in the courtroom as evidence, but would later be shown to not be scientifically valid <span class="citation">(PCAST, 2016, p. 86)</span>.
When a future hangs in the balance of such evidence, we must know that the type of evidence being presented is something that can be relied upon, and that the jury can weigh it appropriately when reaching a conclusion.
One way to assure that these goals are met is through the use of statistical methods in analysis, which allows for the quantification of comparisons and the establishment of accurate error rate calculations.
However, these statistical methods more difficult for jurors to understand.</p>
<p>By testing jury perception in bullet matching, and developing tools for assessing jury perception, we hope to expand what can be learned about jury perception in order to present statistical methods in a way that can be understood and used to make decisions by the wider public.
Bullet matching has a history similar to many areas of forensic pattern evidence, and we have to statistically validate its use before it should be used in the courtroom or treated as reliable evidence.
However, we must also establish that jurors can treat the evidence with appropriate weight.</p>
</div>
<div id="bullet-matching-background" class="section level2 hasAnchor" number="1.2">
<h2><span class="header-section-number">1.2</span> Bullet Matching Background<a href="index.html#bullet-matching-background" class="anchor-section" aria-label="Anchor link to header"></a></h2>
In firearms evidence, there are two pieces of fired evidence that may be evaluated: the cartridge casing and the bullet itself.
The structure of the bullet is shown in Figure <a href="index.html#fig:structure">1.1</a> <span class="citation">(Glrx, 2021)</span>.
Striation marks are created on the bullet as it travels down the barrel due to rifling, defects, and impurities <span class="citation">(Hare, Hofmann, Carriquiry, et al., 2017)</span>, while the head of the cartridge casing is marked by the breech face <span class="citation">(Laboratory, 2024)</span>) and aperture sheer <span class="citation">(NC Crime Lab, 2021)</span>) <span class="citation">(Chapnick et al., 2021)</span>.
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:structure"></span>
<img src="images/Cartridge_cross_section.png" alt="Image of bullet structure. 1 indicates the bullet, 2 indicates the cartridge casing, 3 indicates the powder, 4 indicates the head of the cartridge casing, and 5 indicates the primer. Glrx (2021)." width="50%" />
<p class="caption">
Figure 1.1: Image of bullet structure. 1 indicates the bullet, 2 indicates the cartridge casing, 3 indicates the powder, 4 indicates the head of the cartridge casing, and 5 indicates the primer. Glrx (2021).
</p>
</div>
<p>The practice of bullet matching is based on the concept that rifling in a gun barrel can produce uniquely identifying marks on bullets fired from the gun, due to random variation <span class="citation">(PCAST, 2016, p. 104)</span>.
<a href="index.html#fig:rifling">1.2</a> <span class="citation">(baku13, 2005)</span>.
</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:rifling"></span>
<img src="images/rifling.jpg" alt="Cross section of a gun. The rifling is the spiral pattern of lands (raised portions) and grooves (indented portions). baku13 (2005)." width="50%" />
<p class="caption">
Figure 1.2: Cross section of a gun. The rifling is the spiral pattern of lands (raised portions) and grooves (indented portions). baku13 (2005).
</p>
</div>
<p> <a href="index.html#fig:fired">1.3</a> <span class="citation">(Gremi-ch, 2009)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fired"></span>
<img src="images/fired_bullet.jpg" alt="Fired bullet. Indented portion correspond to the gun lands. Gremi-ch (2009)." width="50%" />
<p class="caption">
Figure 1.3: Fired bullet. Indented portion correspond to the gun lands. Gremi-ch (2009).
</p>
</div>
<p> <a href="index.html#fig:fireddiagram">1.4</a> from <span class="citation">Hare et al. (2017)</span> </p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fireddiagram"></span>
<img src="images/bulletdiagram.jpg" alt="Diagram of a fired bullet. Hare et al. (2017)." width="50%" />
<p class="caption">
Figure 1.4: Diagram of a fired bullet. Hare et al. (2017).
</p>
</div>
<p> <a href="index.html#fig:firedland">1.5</a> <span class="citation">Hare et al. (2017)</span>).
</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:firedland"></span>
<img src="images/bulletland.jpg" alt="Side view of a fired bullet, demonstrating striation marks on the bullet's lands. Hare et al. (2017)." width="50%" />
<p class="caption">
Figure 1.5: Side view of a fired bullet, demonstrating striation marks on the bullet’s lands. Hare et al. (2017).
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:microscope"></span>
<img src="images/microscope.jpg" alt="Image of a comparison microscope and aligned bullets" width="50%" />
<p class="caption">
Figure 1.6: Image of a comparison microscope and aligned bullets
</p>
</div>
<p> Figure <a href="index.html#fig:microscope">1.6</a>,
An early attempt to distinguish guns based on the rifling can be found in two issues of “The Saturday Evening Post” from 1925, in an article entitled “Fingerprinting Bullets” <span class="citation">(PCAST, 2016, p. 91)</span>.
Stout describes the wrongful conviction and subsequent exoneration of Stielow, who was accused of murder <span class="citation">(Stout, 1925a)</span>.
At the trial where Stielow was found guilty, an expert for the prosecution stated that there were nine abnormalities on Stielow’s gun that corresponded with marks on the fired bullet <span class="citation">(Stout, 1925a, p. 7)</span>.
It was later established that the bullet found at the crime scene indicated the gun was missing a land – leaving a distinctive pattern – while the alleged gun showed no such evidence; the alleged gun also showed evidence of not being fired in more than 3 years <span class="citation">(Stout, 1925a)</span>.</p>
<p>While this trial did not require ‘uniquely identifying’ marks to rule out the alleged weapon (only a mismatch in lands), it motivated Charles Waite to attempt to catalog the manufacturing methods of guns by various companies around the country, with the goal of connecting a gun to its manufacturer.
Waite soon encountered issues due to the multitude of guns produced abroad, as well as “cheap knock-offs” with no clear record, making it difficult to trace a gun or bullet to its manufacturer <span class="citation">(Stout, 1925b)</span>.
While Waite’s early attempt to match barrel markings to specific gun brands was focused on the creation of a ‘database’, more recent firearms identification methods have relied on the direct comparison of bullets, such as comparing fired evidence to a suspected gun.</p>
</div>
<div id="issues-in-pattern-analysis" class="section level2 hasAnchor" number="1.3">
<h2><span class="header-section-number">1.3</span> Issues in Pattern Analysis<a href="index.html#issues-in-pattern-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="subjectivity-of-comparisons" class="section level3 hasAnchor" number="1.3.1">
<h3><span class="header-section-number">1.3.1</span> Subjectivity of Comparisons<a href="index.html#subjectivity-of-comparisons" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One of the issues discussed in <span class="citation">Stout (1925a)</span> still resonates today: disagreement among experts; this can be especially problematic in countries that use the adversarial judicial system, where experts can testify on the side of the prosecution or the defense.
<span class="citation">NRC (2009)</span> states that subjectivity is involved in determining “sufficient agreement” among firearms.
<!-- (155). -->
This issue is also reflected in <span class="citation">Imwinkelried (2020)</span>, who suggest that bullet identification is based more on personal experience than on the scientific method.
In plain terms, there is not a set standard for what constitutes sufficient agreement between compared evidence.</p>
<p>Because there is no quantitative score describing the strength of a bullet match, it is possible for experts to use different criterion when making a conclusion about the same evidence.
Disagreement among experts concerning strength of evidence can even be found within a single lab, where experts undergo the same training, use the same equipment and operate under the same procedures, as demonstrated by <span class="citation">Montani, Marquis, Egli Anthonioz, &amp; Champod (2019)</span>.
<span class="citation">(Mattijssen, Witteman, Berger, &amp; Stoel, 2020)</span>.</p>
<p>Research has been conducted to better understand the factors that drive firearms examiners to make their conclusions.
The use of virtual comparisons allowed <span class="citation">Chapnick et al. (2021)</span> to investigate what examiners considered important when evaluating cartridge cases by including a feature to highlight important aspects of comparisons.
They found that examiners generally tended to highlight the same features when making match conclusions <span class="citation">(Chapnick et al., 2021, p. 8)</span>.
However, not all examiners who correctly identified the samples used ‘irregularly shaped marks’ to distinguish the known matches: the number was around 60%-70% <span class="citation">(Chapnick et al., 2021, p. 6)</span>.
This is far from a unanimous consensus on important features for determining a match in this type of firearm evidence.
<span class="citation">(Superior Court of California, 2021, p. 98)</span>.
<span class="citation">(NRC, 2009, p. 202)</span>.
</p>
<p>Procedural issues may also lead to differing expert opinions across laboratories; one system may not allow an exclusion to be documented if the class characteristics match, while another system may not have such a limitation <span class="citation">(Baldwin, Bajic, Morris, &amp; Zamzow, 2014, p. 6)</span>.
In their study, this led to 45 of 218 examiners labeling all different source comparisons as inconclusive, and 96 examiners labeling none of the comparisons as inconclusive <span class="citation">(Baldwin et al., 2014, p. 16)</span>.
Without a standardized procedure, experts evaluate the evidence similarly when comparing two bullets, but must draw different conclusions based on the procedures of their laboratory.
This in inconsistencies in results based on location, which are compounded with inconsistencies that may arise due to the subjectivity of bullet comparisons.</p>
<p>Aside from the difference in evaluation , subjectivity can lead to bias in pattern recognition.
The need for an unbiased method of evaluation is aptly demonstrated by the case of the Madrid bombing, in which the FBI incorrectly matched a latent fingerprint to individual, despite the use of a verification process <span class="citation">(Stacey, 2005)</span>.
The individual incorrectly identified was a Muslim from Oregon who had been on an FBI watch list <span class="citation">(Kassin, Dror, &amp; Kukucka, 2013, p. 42)</span>.
<span class="citation">Kassin et al. (2013)</span> suggest that this incorrect conclusion may relate to confirmation bias, and outline other contributing factors, such as extraneous details, external pressures, and order of presentation.
While this example is based on fingerprint analysis, the same issues of subjectivity are present in bullet matching.</p>
<p><span class="citation">Mattijssen, Witteman, Berger, &amp; Stoel (2020)</span> <span class="citation">Mattijssen, Witteman, Berger, &amp; Stoel (2020)</span>
<span class="citation">Montani et al. (2019)</span> discuss the importance of independent verification, and how to present results when experts do not agree.
They suggest that, when experts disagree, a third expert should be consulted, and all conclusions should be documented and presented as evidence.
<span class="citation">Mattijssen, Witteman, Berger, &amp; Stoel (2020)</span>.</p>
<p>While there are issues in subjective bullet matching, there have been attempts .
<span class="citation">Biasotti (1959)</span> suggests that statistical methods can be used in order to determine whether two bullets were fired from the same gun.
He concludes that evaluation of individual striation marks is not sufficient, but counting the number of consecutively matching lines may provide enough information to distinguish between matching and non-matching bullets, in the case of the .38 Special Smith and Wesson revolvers used in this study <span class="citation">(Biasotti, 1959, p. 37 – 47)</span>.
<span class="citation">Biasotti (1959)</span> hoped that such methods may lead to a statistical model for evaluating firearms (47).
The idea of consecutively matching striae (CMS) was addressed again in <span class="citation">S. G. Bunch (2000)</span>, but a completely standardized or quantifiable method of examination has yet to be developed.
According to Weller, consecutively matching striae is still used today by some examiners; however, this process has not been nationally adopted <span class="citation">(Superior Court of California, 2021, p. 98)</span>.
<span class="citation">Biasotti (1959)</span>’s idea of using consecutively matching lines is used and extended in the bullet matching algorithm developed by <span class="citation">Hare et al. (2017)</span>.</p>
</div>
<div id="scientific-validity" class="section level3 hasAnchor" number="1.3.2">
<h3><span class="header-section-number">1.3.2</span> Scientific Validity<a href="index.html#scientific-validity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In recent years, the scientific validity of many forensic science methods have been called into question, as shown in the <span class="citation">NRC (2009)</span> and <span class="citation">PCAST (2016)</span> reports on feature comparison methods.
General concerns in both reports include foundational evidence for scientific validity, general inability to determine error rates for conclusions, and subjectivity in analysis methods.
Some issues outlined by <span class="citation">PCAST (2016)</span> are the circular nature of the identification guidelines and the lack of appropriately designed error rate studies.
<!-- (104).  -->
AFTE defines sufficient agreement as “…the examiner being convinced that the items are extremely unlikely to have a different origin” <span class="citation">(PCAST, 2016, p. 104)</span>.
Thus, items are classified as having sufficient agreement if they agree sufficiently enough to conclude that they did not come from different sources.
This guideline is in itself subjective - there are no benchmarks for determining what one means by “extremely unlikely to have a different origin”.
Both <span class="citation">NRC (2009)</span> and <span class="citation">PCAST (2016)</span> suggest a move away from subjective methods.
<span class="citation">PCAST (2016)</span> states the importance of the development of an objective method for firearms comparisons.
<!-- (113).  --></p>
<p>These reports also highlighted the lack of studies that produced accurate error rates due to several issues, such as the reporting of inconclusive decisions as well as simple design issues <span class="citation">(PCAST, 2016, p. 104 - 112)</span>.
For example, <span class="citation">Chapnick et al. (2021)</span>’s report does not include inconclusive results as a potential source of error.
They reported three errors (false positives) in their study, and reported a false negative error rate of 0%, ignoring the wide range of inconclusive decisions.
For participants from the United States and Canada, 38 of 491 comparisons were reported as inconclusive for known matches, while 254 of 693 comparisons were reported as inconclusive for know non-matches <span class="citation">(Chapnick et al., 2021, p. 6)</span>.
The issues of error rate calculation are addressed by <span class="citation">Hofmann, Vanderplas, &amp; Carriquiry (2021)</span>, particularly with regards to whether or not inconclusive decisions should be treated as errors in calculations. <!-- (325) -->
They suggest to not consider inconclusive decisions as errors for the calculation of examiner error rates, used in the lab setting; but to consider inconclusive decisions as errors for process error rates, used for determining if the evidence is relevant enough for judging the guilt of the suspect. <!-- (343) -->
This distinction would allow an examiner to report an inconclusive finding without a negative reflection on their work, as inconclusive decisions are sometimes necessary.
But it would also provide jurors with relevant information for evaluating the reliability of firearms evidence.</p>
<p>In another evaluation of inconclusive results, <span class="citation">Dror &amp; Scurich (2020)</span> describe different ways in which inconclusive results are produced.
They differentiate between inconclusive decisions based on the amount of evidence present; an examiner reaching an inconclusive decision when there is not sufficient evidence to reach a conclusion would be correct, whereas an examiner reaching an inconclusive decision when there is sufficient evidence to reach a conclusion would be incorrect. <!-- (334) -->
This definition relies on amount of evidence necessary to reach a conclusive decision.
By failing to distinguish between correct and incorrect inconclusive decisions in research studies, examiners may opt for the inconclusive choice on hard conclusive comparisons, resulting in error rates that are only valid for easy comparisons when inconclusive decisions are not considered an error<span class="citation">(Dror &amp; Scurich, 2020, p. 336)</span>.
<span class="citation">Dror &amp; Scurich (2020)</span> would consider those inconclusive choices to be “incorrect” - there is enough evidence to reach a conclusion.
Similarly, another potential error would be the examiner reaching a conclusive decision when there is not sufficient evidence to reach a conclusion <span class="citation">(Dror &amp; Scurich, 2020, p. 334)</span>.
This delineates conclusion and errors into distinct categories, which are not seen in error rate studies.</p>
<p>Both inconclusive and conclusive results for the same analysis cannot be correct – there either is enough evidence to make a conclusion, or there is not enough evidence to make a conclusion; to say otherwise may deflate actual error rates <span class="citation">(Dror &amp; Scurich, 2020, pp. 334–335)</span>.
<span class="citation">Dror &amp; Scurich (2020)</span> indicate that this inconclusive issue is more prominent in studies than in casework, as inconclusive decisions are more common in error rate studies. <!-- (336) -->
<span class="citation">Hofmann et al. (2021)</span>
, this distinction is not commonly made in studies due to the lack of a quantifiable method for separating the two categories, leading to inconclusive decisions lowering the error rate in some studies.</p>
<p> <span class="citation">(Hofmann et al., 2021)</span>.
As <span class="citation">Hofmann et al. (2021)</span> </p>
<p>Other issues in the computation of error rates include the use of closed set studies, which result in significantly lower rates of inconclusive decisions and false positives <span class="citation">(PCAST, 2016, p. 109)</span>. In closed set studies, the source gun is always present, and examiners are asked to match a set of known bullets to a set of unknown bullets - allowing for them to use a process of elimination to make matches; conversely, open set studies do not include all source guns <span class="citation">(PCAST, 2016, pp. 108–110)</span>.
The Ames Laboratory study is described by <span class="citation">PCAST (2016)</span> as an appropriate closed set black-box study (111).
These types of analyses are classified as black-box studies because reported match results are based on an examiner’s subjective opinion rather than a list of objective steps <span class="citation">(PCAST, 2016, p. 5)</span>.
When comparing closed-set studies to non closed-set studies, <span class="citation">PCAST (2016)</span> found that closed-set studies had a much lower rate of inconclusive decisions as well as false positives (111).</p>
<p>This debate regarding scientific validity continues to this day, as <span class="citation">Vanderplas, Khan, Hofmann, &amp; Carriquiry (2022)</span> shows.
In this declaration, they discuss the current issues with error rate studies, in which they conclude that, until valid error rate studies have been conducted, they cannot support the use of firearms analysis in the courtroom <span class="citation">(Vanderplas et al., 2022, p. 10)</span>.
Others have called to scale back conclusions that attest to “individualization” in the courtroom due to the inability to tie a specific piece of evidence to a specific source, to the exclusion of all other sources <span class="citation">(Imwinkelried, 2020; NRC, 2009)</span>.
There has been some resistance to scaling back conclusions, however, as demonstrated in a memo sent out by Jim Agar II, an FBI attorney.
They stated that less conclusive language would not be truthful on the part of the firearm expert and to ask firearms examiners to use this language would result in perjury <span class="citation">(Agar II, 2021)</span>, despite the reliance on subjective methods with unclear error rates.</p>
<p>There has also been some push back against the conclusions of <span class="citation">PCAST (2016)</span>, as shown in <span class="citation">OSAC (2016)</span> (provided by the Firearms and Toolmarks subcommittee).
According to <span class="citation">Davis &amp; Baker (2014)</span>, the Organization of Scientific Area Committees (OSAC) subcommittees are “generally composed of 70% practitioners, 20% researchers, and 10% research and development technology partners and providers”.
<span class="citation">OSAC (2016)</span> argue that a false positive error rate is not necessary for determining foundational validity, and that closed set error rate studies are fine for calculating error rates.
<span class="citation">OSAC (2016)</span> also suggests that <span class="citation">PCAST (2016)</span> ignores the importance of peer review in studies that instruct firearms examiners to work alone, and that black box studies may not properly reflect casework.
However, in order to accurately represent casework, blind testing (where the examiner does not know they are being tested) would be needed - but due to logistical issues and case load, this may not be feasible <span class="citation">(PCAST, 2016, p. 59)</span>.
<span class="citation">OSAC (2016)</span> argues that AFTE language is not circular - the basis of a practical impossibility is based on knowledge of best known non-matches conveyed through training.
Here decisions are based on “knowledge and experience”, which does not counteract the subjective nature of this decision making.
Despite these disagreements, <span class="citation">OSAC (2016)</span> also promotes the use of more objective methods.</p>
<p><em>Frye vs. United States</em> <span class="citation">(NRC, 2009, p. 88)</span>.
<em>Frye</em> <em>Daubert v. Merrell Dow Pharmaceuticals, Inc.</em>, <em>Frye</em> <span class="citation">(NRC, 2009, pp. 89–91)</span>.
<span class="citation">(NRC, 2009, p. 94)</span>.
<em>United States v. Green</em>, <em>Daubert</em> <span class="citation">(NRC, 2009, p. 108)</span>.</p>
</div>
<div id="language-in-the-courtroom" class="section level3 hasAnchor" number="1.3.3">
<h3><span class="header-section-number">1.3.3</span> Language in the Courtroom<a href="index.html#language-in-the-courtroom" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>These differing views are represented in <span class="citation">Swofford &amp; Champod (2022)</span>.
<span class="citation">Swofford &amp; Champod (2022)</span> interviewed 15 individuals with a range of expertise in forensic science and the court system in order to assess their feelings about the use of algorithms and the presentation of probabilistic reporting, as opposed to categorical reporting and traditional analysis methods.
They found that prosecutors supported the use of match terms such as “identification” and “individualization” instead of probabilistic terms, but two of the prosecutors also rejected the use of terms that convey “absolute certainty” (p. 7).
All participants felt that that examiner testimony should accurately reflect scientific limitations, although there was not a consensus on whether this practice was in fact followed in the courtroom - defense attorneys felt that the examiners usually do not uphold this expectation, while lab managers expressed frustration on the part of the court (p. 19).
The scale to which firearm evidence is used in the courtroom is rather contentious, and views may differ based on occupation.</p>
<p>In general, individuals want to guarantee that the information presented in the courtroom is accurate and valid, without causing too much imbalance between the limitations and the categorical conclusion.
However, there isn’t agreement on where the balancing point between these two factors are - somewhere between giving too much credit with a match of “absolute certainty”, and introducing unfounded reasonable doubt by overstating the limitations.
If accurate numerical information on error rates or an objective method of evaluation that can be described to the court were available, it may be possible to have factual statements of limitations and scope of evidence that both sides of the argument would find satisfactory.
In an investigation on the effect of the inclusion of error rate on either voice or fingerprint evidence, <span class="citation">Garrett, Crozier, &amp; Grady (2020)</span> found that the inclusion of an error rate reduced convictions for fingerprint evidence presented categorically, but had no effect in the case of voice comparison (a less established science) or when the fingerprint comparison was presented as a likelihood ratio.
They state, “This suggests that error rate information is particularly important for types of forensic evidence that people may assume are highly reliable.” (p. 1206).
Including error rates for evidence methods seen as reliable may call into question some assumptions participants make about the science, resulting in a closer consideration of the facts presented at trial.</p>
<p>f both limitations (in terms of error rates) and the language experts use to present evidence.
While there is much debate over the language used in these conclusions, <span class="citation">Garrett &amp; Mitchell (2013)</span> found that the specific language used to describe the strength of the match (when a match was present) had little effect on participants’ judgement of guilt. They tested 11 different forms of match language, such as ‘individualization’, ‘match’, or ‘very likely that the defendant was the source’, as well as language that included match conclusions ‘bolstered’ by certainty or likelihood language <span class="citation">(Garrett &amp; Mitchell, 2013, p. 489)</span>.
<span class="citation">McQuiston-Surrett &amp; Saks (2009)</span> also found that there was not a significant difference in participants’ view of the likelihood the defendant committed the crime when the examiner presented the conclusion as a ‘match’ compared to presenting the conclusion as ‘similar in all microscopic characteristics.’
<span class="citation">Garrett &amp; Mitchell (2013)</span> suggests that this lack of difference may relate to the overall view of firearms evidence as reliable, meaning that even a weak match simply boils down to being a match in the eyes of the participants (p. 507).</p>
<p>They also found some tempering effect of the expert admitting the possibility that their conclusion was made in error (p. 507).
Thus, the use of accurate error rates may moderate the reliability of experts for a more considered weighing of evidence.
In fact, in the Ninth Judicial Circuit Court, there are suggested jury instructions regarding the need for juries to treat in the same manner as other opinion testimony, where they must decide how much weight the testimony should receive <span class="citation">(United States Courts for the Ninth Circuit, 2019)</span>.
<span class="citation">United States Courts for the Ninth Circuit (2019)</span> also suggest to avoid labeling such testimony as expert testimony , since it may cause jurors to give the testimony undue weight.
One way to fix these issues of subjectivity is by developing a more objective method of evaluation.
One objective method introduced to the forensic sciences is bullet matching algorithms, such as the one described in <span class="citation">Hare et al. (2017)</span>.</p>
</div>
</div>
<div id="quantitative-methods" class="section level2 hasAnchor" number="1.4">
<h2><span class="header-section-number">1.4</span> Quantitative Methods<a href="index.html#quantitative-methods" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="bullet-matching-algorithm" class="section level3 hasAnchor" number="1.4.1">
<h3><span class="header-section-number">1.4.1</span> Bullet Matching Algorithm<a href="index.html#bullet-matching-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="citation">Hare et al. (2017)</span> developed a bullet matching algorithm that uses a random forest in order to determine a match score.
<!-- (p. 2352).  -->
This algorithm can be described as follows:</p>
<ul>
<li>The algorithm first takes a 3D scan of the two bullet lands, then identifies a cross section, or a stable area of the bullet land that can be used in comparison.</li>
<li>This cross section is used in order to identify the signatures of the bullets, or a 2D line that captures the marks scratched onto the bullet’s surface.</li>
<li>The shoulders (the raised area on either side of the scratched pattern) must be removed from the cross section.</li>
<li>A loess smoothing is applied twice in order to remove the curvature of the bullet.
What is left is the bullet land’s signature (which will show the peaks and valleys produced by the barrel of the gun).</li>
<li>The two signatures are compared using a variety of attributes, such as consecutively matching striae and the relative height of the peaks/valleys, as shown in Figure <a href="index.html#fig:signaturecompare">1.7</a>.</li>
<li>A random forest is used to compare the two signatures and generate a match score for the lands.</li>
<li>Lands are then aligned across the bullet for the maximal random forest score, and match score for the bullet.
Figure <a href="index.html#fig:gridcompare">1.8</a> shows two grids of land match scores computed in two different bullet comparisons.</li>
</ul>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:signaturecompare"></span>
<img src="images/Match_Signatures.jpg" alt="Left image depicts two matching signatures, while the right image depicts two non-matching signatures. Generated by the author." width="49%" /><img src="images/K995_NoMatch_Signatures.jpg" alt="Left image depicts two matching signatures, while the right image depicts two non-matching signatures. Generated by the author." width="49%" />
<p class="caption">
Figure 1.7: Left image depicts two matching signatures, while the right image depicts two non-matching signatures. Generated by the author.
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gridcompare"></span>
<img src="images/F526_Match_SingleGrid.png" alt="Left image depicts two matching bullets (indicated by high land-to-land match scores in a diagonal formation), while the right image depicts two non-matching bullets. Generated by the author," width="49%" /><img src="images/K995_NoMatch_SingleGrid.png" alt="Left image depicts two matching bullets (indicated by high land-to-land match scores in a diagonal formation), while the right image depicts two non-matching bullets. Generated by the author," width="49%" />
<p class="caption">
Figure 1.8: Left image depicts two matching bullets (indicated by high land-to-land match scores in a diagonal formation), while the right image depicts two non-matching bullets. Generated by the author,
</p>
</div>
<p>In multiple tests, it was found that the algorithm is able to successfully distinguish between known matches and known non-matches without the use of an inconclusive decision <span class="citation">(Vanderplas, Nally, Klep, Cadevall, &amp; Hofmann, 2020, p. 10)</span>.
If the bullet is not fit for algorithmic comparison, then an ‘inconclusive’ result may still be reached.
This could be the case for gun types that have not been tested for the algorithm.
The use of an algorithm allows for quantification of bullet matching, for cases where the algorithm has been verified.</p>
<p>There are some concerns about .
<span class="citation">Garrett &amp; Rudin (2023)</span> explain one main issue that may result from “black box” algorithmic methods: the results from the algorithm may not be accurate, and this may be difficult to discern when individuals do not understand the method used.
They instead suggest the use of “glass box” methods, where the algorithm’s model is interpretable (people can see how it works, and what information is used to make decisions).
<span class="citation">Garrett &amp; Rudin (2023)</span> state that “…interpretability is particularly important in legal settings, where human users of a system… cannot fairly and accurately use what they cannot understand.”.
This brings up a particularly salient point in jury trials - jurors should understand the pattern comparison process if they are making decisions based on its results.</p>
<p>In a combination of computerized results and human interpretation, <span class="citation">Montani et al. (2019)</span> suggest presenting the algorithm as a “second independent expert” whose comparison and conclusion can be compared to and presented alongside the examiner’s.
Supplementing the decision of the forensic expert with an algorithm would allow for verification of results in two independent methods.
The three laboratory managers interviewed by <span class="citation">Swofford &amp; Champod (2022)</span> suggested using algorithms as a supplement to the forensic examiner (p. 6), similar to <span class="citation">Montani et al. (2019)</span>’s suggestion.</p>
<p>The three prosecutors varied in their feelings of algorithms in the courtroom: one thought that they would add unnecessary complications, while two suggested that the algorithms may be useful for the forensic expert <span class="citation">(Swofford &amp; Champod, 2022, p. 8)</span>.
The three defense attorneys, as well as the three judges, also supported the use of algorithms as empirical evidence, while stating concerns of transparency <span class="citation">(Swofford &amp; Champod, 2022, pp. 10–13)</span>.
Three academic scholars supported the use of algorithms, so long as the algorithms can be understood, have been validated, and do not include factors that may cause systematic biases <span class="citation">(Swofford &amp; Champod, 2022, p. 16)</span>.
<span class="citation">Swofford &amp; Champod (2022)</span>’s study demonstrates the variety of opinions on algorithm implementation throughout forensic science, although most support the use of algorithms.</p>
</div>
<div id="reporting-quantitative-results" class="section level3 hasAnchor" number="1.4.2">
<h3><span class="header-section-number">1.4.2</span> Reporting Quantitative Results<a href="index.html#reporting-quantitative-results" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Quantitative methods of examination can lead to quantitative results.
In this case, the quantitative results are in the form of a match score, but in other cases, results may be presented as a likelihood ratio.
<span class="citation">(Ommen &amp; Saunders, 2021)</span>.
<span class="citation">Ommen &amp; Saunders (2021)</span>. <span class="math inline">\(\frac{P(E|H_p)}{P(E|H_d)}\)</span>,
<span class="citation">Ommen &amp; Saunders (2021)</span> <span class="math inline">\(\frac{P(E|H_p)}{P(E|H_d)}\)</span>.</p>
<p><span class="citation">John Song, Chen, Vorburger, &amp; Soons (2020)</span> proposed a likelihood approach for a cartridge case comparison method that uses congruently matching cells.
This is a change from the match language usually used by forensic examiners, but these likelihood ratios may have some benefit.
<span class="citation">Marquis et al. (2016)</span> suggest that the use of a likelihood ratio requires examiners to consider what they are including when weighing the strength of evidence, and provides a value that can be consistent across disciplines (p. 4).
This quantitative approach, even while conducting a subjective evaluation, is meant to prevent examiners from being biased by information provided outside of their direct examination <span class="citation">(S. Bunch &amp; Wevers, 2013, p. 223)</span>.
The approach also asks examiners to consider both the null and alternative hypotheses, and may make it less likely for either the examiners or jurors to transpose the conditional, which may happen in the case of reporting probabilities <span class="citation">(Evett, 1998; Marquis et al., 2016, p. 3)</span>.</p>
<p>As an example of transposing the conditional, suppose an examiner were comparing a bullet from the suspect’s gun to a bullet recovered from the crime scene.
The examiner may find that there is significant agreement between the two bullets.
They may then conclude that “the probability of seeing such significant agreement between the two bullets <em>given that another gun fired the bullet at the crime scene</em> is small”.
In this case, the examiner is making a statement regarding the amount of agreement between the two bullets (P(Correspondence|Different Source)).
If the conditional is transposed, the statement would become “the probability that another gun fired the bullet at the crime scene <em>given the significant agreement between the two bullets</em> is small” (P(Different Source|Correspondence)).
Here, the conditional part of the statement has been switched, so that the examiner is making a statement regarding the gun being fired at the crime scene instead of a statement with regards to the bullet comparison.
By stating a likelihood ratio, such as “the bullet comparison provides strong support for the proposition that the two bullets came from the same gun rather than the proposition that the two bullets came from different guns”, both the null and alternative hypothesis are clearly stated, and the focus of the statement is on the bullet comparison, rather than the gun’s presence at the crime scene.</p>
<p>As shown above, the likelihood ratio directly compares the null and alternative hypotheses in a case, which is not accomplished by considering a single probability <span class="citation">(Nordgaard, Ansell, Drotz, &amp; Jaeger, 2012, p. 6)</span>.
Likelihood ratios also allow for the integration of evidence from multiple sources, and individual likelihood ratios may be multiplied together to calculate an overall likelihood ratio <span class="citation">(Marquis et al., 2016; Nordgaard et al., 2012)</span>.
<span class="citation">Meuwly, Ramos, &amp; Haraksim (2017)</span> suggested guidelines for validating both score- and feature-based likelihood ratio methods, so this form of result presentation could be more widely accepted.
These methods included validation criteria for all variables considered in a likelihood ratio, where validation criteria can be considered in several ways: a comparison with current “state of the art” methods, detection error trade-off graphs to measure discriminating power, and performing validation on a validation data set.</p>
</div>
<div id="explainability-in-the-courtroom" class="section level3 hasAnchor" number="1.4.3">
<h3><span class="header-section-number">1.4.3</span> Explainability in the Courtroom<a href="index.html#explainability-in-the-courtroom" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One roadblock in the use of quantitative methods and results, such as likelihood ratios, in the forensic sciences is the necessity to explain such methods to jurors so that they can understand the method and results well enough to make informed decisions in court cases.
<span class="citation">Association of Forensic Science Providers (2009)</span> stated that opinions and conclusions should be expressed in likelihood ratios when outlining guidelines for forensic experts.
<!-- (p. 163).  -->
Participants in <span class="citation">Swofford &amp; Champod (2022)</span> expressed concern that probabilistic reporting would be confusing and easily misinterpreted, when compared to the alternative of categorical reporting.
<!-- (p. 18). -->
In order to gauge how quantitative methods are perceived in the courtroom, we can consider fingerprint and DNA analysis.
<span class="citation">Garrett, Mitchell, &amp; Scurich (2018)</span> studied the use of FRStat for fingerprint matching in the courtroom.
The FRStat language presented to the study participants is as follows: “The probability of observing this amount of correspondence is approximately [XXX] times greater when the impressions are made by the same source rather than by different sources” <span class="citation">(language from Defense Forensic Science Center, 2018)</span>.
<span class="citation">Garrett et al. (2018)</span> used ratios from 10 times greater to 100,000 times greater, and found that the likelihood that the subject committed the crime according to the participants did not change significantly.
This demonstrates that potential jurors may have trouble accurately interpreting statistical results, including likelihood ratios.</p>
<p>In DNA research, <span class="citation">Koehler (2001)</span> found that participants were more likely to believe the subject was the source of the DNA when presented with a probability instead of a frequency.
When asked about how many individuals would match DNA for a given match proportion in a population of 500,000, 60.7% of participants who received a frequency and 42.1% of individuals who received a probability answered correctly <span class="citation">(Koehler, 2001, p. 503)</span>.
When asking these individuals to determine the guilt or innocence of a suspect, the percentage of participants who correctly interpreted the DNA results seems relatively low.
Jurors are also prone to find evidence to be weaker when frequencies are presented as whole number (1 out of 100,000) compared to a decimal number (0.1 out of 10,000), even though the frequencies represent the same value <span class="citation">(Koehler &amp; Macchi, 2004, p. 544)</span>.
These studies show that individuals struggle with interpreting numerical results, and assigning appropriate weight to likelihood ratios.</p>
<p>In addressing these issues of interpretation, attempts have been made to assign a verbal scale to be used alongside a likelihood ratio, such as the European recommendations for reporting forensic science <span class="citation">(ENFSI, 2016)</span>.
A sample of phrasing from their recommended scale has been recreated in Table <a href="index.html#tab:enfsi">1.1</a>.
Verbal values range from no support to extremely strong support, and correspond to a numerical output.
This type of scale would present jurors with both the quantitative result as well as a brief interpretation, so they are not solely relying on their own perception of what the likelihood ratio qualitatively means.
It also offers a numerical scale that may encourage consistency across examiner reports.</p>
<table>
<caption><span id="tab:enfsi">Table 1.1: </span> Sample language from <span class="citation">ENFSI (2016)</span> (17)</caption>
<colgroup>
<col width="20%" />
<col width="79%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Likelihood Ratio</th>
<th align="center">Verbal Equivalent</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">The forensic findings do not support one proposition over the other</td>
</tr>
<tr class="even">
<td align="center">2 - 10</td>
<td align="center">The forensic findings provide weak support for the first proposition relative to the alternative</td>
</tr>
<tr class="odd">
<td align="center">10 - 100</td>
<td align="center">…provide moderate support for the first proposition rather than the alternative</td>
</tr>
<tr class="even">
<td align="center">100 - 1,000</td>
<td align="center">…provide moderately strong support for the first proposition rather than the alternative</td>
</tr>
<tr class="odd">
<td align="center">1,000 - 10,000</td>
<td align="center">…provide strong support for the first proposition rather than the alternative</td>
</tr>
<tr class="even">
<td align="center">10,000 - 1,000,000</td>
<td align="center">…provide very strong support for the first proposition rather than the alternative</td>
</tr>
<tr class="odd">
<td align="center">1,000,000 and above</td>
<td align="center">…provide extremely strong support for the first proposition rather than the alternative</td>
</tr>
</tbody>
</table>
<p>A similar scale is also suggested by <span class="citation">Evett (1998)</span>, with verbal values of “Limited support”, “Moderate support”, “Strong support”, and “Very strong support” (p. 201).
These values approximately correspond to the scale above, but consists of fewer categories.
<span class="citation">Marquis et al. (2016)</span> suggest against providing the full verbal scale to participants, because participants may use other terms on the scale in order to orient the likelihood ratio in comparison to the full scale.
<!-- (p. 7).  -->
However, this ability to orient relative to other values may assist jurors in accurately judging the strength of evidence presented.</p>
<p>While verbal scales are useful for clarification, individuals may not always interpret them consistently.
For example, <span class="citation">Budescu &amp; Wallsten (1985)</span> asked participants to rank common probabilistic words (such are “rarely” or “usually”) on three separate occasions, finding that individuals typically gave consistent rankings across time points, but there was variation in rankings between individuals.
In an earlier study, <span class="citation">Lichtenstein &amp; Newman (1967)</span> asked individuals to assign numerical probabilities to probabilistic words, finding that eight of the eleven mirror terms (such as “quite likely” and “quite unlikely”) demonstrated asymmetry - positive terms (such as likely) scored lower than their mirrored negative terms (unlikely). For example, “quite likely” and “quite unlikely” had median values of 0.8 and 0.1, respectively <span class="citation">(Lichtenstein &amp; Newman, 1967, p. 564)</span>.</p>
<p><span class="citation">Martire, Kemp, Watkins, Sayle, &amp; Newell (2013)</span> studied the use of a verbal scale similar to <span class="citation">ENFSI (2016)</span> in a courtroom setting, in the case of shoe print evidence.
They found a “weak evidence effect”, in which findings that provided “weak support” for the proposition that the defendant’s shoe left the print resulted in decreased likelihood scores of guilt, compared to likelihood scores collected before the introduction of forensic evidence.
<span class="citation">Martire et al. (2013)</span> did not find this trend when the evidence was presented numerically as a likelihood ratio; in this case, participants tended to think of the defendant as more guilty after hearing the forensic evidence (as expected).
They did not, however find that the reverse was true: those who received “weak support” for the proposition that the defendant did not leave the shoe print resulted in increased likelihood scores in favor of innocence, as expected.
<span class="citation">Martire et al. (2013)</span> hypothesize that this demonstrates that the participants are engaging in a “criminal justice perspective” by weighting the evidence toward the defendant’s innocence (since the burden of proof rests on the prosecution).
This inconsistency of interpretation between the numerical scale and the verbal equivalent may act as evidence against implementation of a solely verbal scale.</p>
<p>Examiners also show evidence of inconsistency in scale interpretation.
<span class="citation">Mattijssen, Witteman, Berger, Brand, &amp; Stoel (2020)</span> asked examiners to use a verbal scale for degree of similarity and support when digitally comparing cartridge cases.
When using a verbal scale for degree of similarity/support, <span class="citation">Mattijssen, Witteman, Berger, Brand, et al. (2020)</span> found that the between-subject and within-subject reliability was moderate to high.
<!-- (p. 11).  -->
<span class="citation">Mattijssen, Witteman, Berger, Brand, et al. (2020)</span> asked 10 examiners who regularly used likelihood ratios to provide both a verbal degree of support along with a likelihood ratio.
They found that the verbal degrees of support were in general an overestimation when compared to the likelihood ratios.
<!-- (p. 8).  -->
While this is a small non-representative sample, it suggests that verbal scales do not always correspond to quantitative scales across subjects.
<span class="citation">Thompson &amp; Newman (2015)</span> investigated the amount of weight participants gave either DNA or shoe print evidence when it was presented as a likelihood ratio, verbal equivalent, or random match probability.
While individuals updated their response as expected when the strength of evidence was changed in all cases of the DNA condition, participants did not produce significantly different estimates when shoe print evidence was presented as a likelihood ratio or verbal equivalent, but they did produce different estimates in the case of the random match probability.
These results indicate that participants may weigh evidence differently depending on the presentation method.
<span class="citation">Thompson &amp; Newman (2015)</span> hypothesize that the difference between the DNA results and the shoe print results may stem from the perception of DNA analysis as highly scientific.
By combining the quantitative analysis with a verbal translation, it may be possible to present quantitative results in a manner that is understood consistently by laypeople.</p>
<p>This mix of quantitative language alongside more categorical terms is supported by subjects in <span class="citation">Swofford &amp; Champod (2022)</span>.
Almost all participants expressed concerns about the interpretation of the probabilistic language, and many recommended a combination of both methods <span class="citation">(Swofford &amp; Champod, 2022)</span>.
The prosecutors interviewed thought that match language was sufficient by itself, and did not wish to complicate testimony with probabilistic language <span class="citation">(Swofford &amp; Champod, 2022, p. 8)</span>.
<span class="citation">McQuiston-Surrett &amp; Saks (2009)</span> studied the use of match language versus probabilities with both judges and juries.
Both groups assigned higher probabilities to the defendant committing the crime when presented with qualitative evaluation or a single probability for the hair comparison, as compared to frequency methods of reporting.
<span class="citation">McQuiston-Surrett &amp; Saks (2009)</span> found that participants were more sure of the guilt of the defendant when qualitative language was used as opposed to a subjective probability.
While match language may give jurors more confidence, it could have the effect of shifting the consideration of evidence from the jury (who in a quantitative approach would need to determine whether or not they feel a likelihood ratio is large enough to indicate that the subject is the source) to the forensic expert, who can declare a match.</p>
</div>
<div id="demonstrative-evidence" class="section level3 hasAnchor" number="1.4.4">
<h3><span class="header-section-number">1.4.4</span> Demonstrative Evidence<a href="index.html#demonstrative-evidence" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Aside from result language or scales used , another important factor in jury decision making is demonstrative evidence.
Images can supply helpful context in describing complex forms of analysis, but they may also introduce bias in the form of “truthiness”, a term introduced by comedian Stephen Colbert.
He described truthiness as the quality of something <em>seeming</em> true <span class="citation">(Colbert, 2005)</span>.
In this , Colbert talks about “thinking with your head vs. knowing with your heart”, where some information may feel true, regardless of the facts.
<span class="citation">Bornstein &amp; Greene (2011)</span> found a “truthiness” effect in the courtroom - jurors tend to remember evidence that aligned with their previous beliefs.
<!-- (65).  -->
<span class="citation">Kellermann (2013)</span> suggests that the truthiness or “falsiness” of non-probative visual images should be carefully considered before using images in the courtroom “…both to prevent backfire effects and to capitalize on every possible tactic that can be used to persuade jurors…” (p. 40).
While the concept of truthiness can be used to benefit either side in an adversarial justice system, trial outcomes should be based on factual evidence, rather than feelings that evidence is factual.
In the case of images in trials, it is important to balance the benefit of providing additional information to the jury via images without increasing truthiness.</p>
<p>The impact of photos on an individual’s perception can be rather large, as investigated by <span class="citation">Cardwell, Henkel, Garry, Newman, &amp; Foster (2016)</span>.
They asked individuals to “give” or “take” food from an animal, represented by a word.
Subjects were later asked to identify whether or not they gave food to an animal – either accompanied by an image or not.
Individuals were more likely to say that they gave food to an animal if it was accompanied by an image <span class="citation">(Cardwell et al., 2016)</span>.
<!-- [@cardwellNonprobativePhotosRapidly2016, 887] -->
They found that images had an effect for positive associations such as giving food, but not negative associations such as taking food.
<!-- [@cardwellNonprobativePhotosRapidly2016, 883]. -->
In this case, the use of images may make it easier for individuals to visualize a scenario (giving food), and thus makes them more likely to remember the event - whether it happened or not.</p>
<p>In a study of perception, <span class="citation">McCabe &amp; Castel (2008)</span> presented a variety of graphics alongside articles relating to cognitive neuroscience.
The graphics all contained the same information, which was already presented the accompanying article.
They found that participants gave higher ratings of scientific reasoning to articles that included a brain image with activated areas, as opposed to a bar chart, topographical brain graphic, or no graphic.
Participants were also more likely to agree with the conclusion of an article when the brain image was present, compared to when it was absent.
Although the information presented in the articles did not change throughout these conditions, the brain image appears to add more “truthiness” to the articles, causing individuals to find them more scientific than articles with other graphics or no graphics.</p>
<p>In the courtroom, studies have been conducted to evaluate the effect of images of the brain.
<span class="citation">Gurley &amp; Marcus (2008)</span> studied the use of brain images when arguing the defendant is not guilty by reason of insanity.
In a study on introduction to psychology university students, they found that the inclusion of images showing a brain lesion increased the odds of the participants finding the defendant not guilty by reason of insanity.
MRI scans were presented with additional information regarding impulse control for the damaged area, so the effect may not be caused by the images themselves but rather by the additional information.
<span class="citation">Schweitzer et al. (2011)</span> investigated whether images of the brain presented alongside expert testimony with regards to a mental disorder effected the participant’s verdict of the defendant’s mental state.
In this case, no additional information was provided alongside the neuroimage, allowing the effect of the image itself to be studied.
They found that the inclusion of neuroimages did not significantly effect the judgement of the participants.
The influence of images on individuals remains unclear, and may be situationally dependent.</p>
</div>
</div>
<div id="response-methods" class="section level2 hasAnchor" number="1.5">
<h2><span class="header-section-number">1.5</span> Response Methods<a href="index.html#response-methods" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p> <span class="citation">(Groves et al., 2009)</span>.
Verbal scales, such as those used in the ENFSI guidelines described in the last section, are often used to record participant responses.
Likert scales can be used to evaluate several factors, such as the reliability, understanding, and scientific quality of the forensics expert, the algorithm, and the testimony in general.
It is therefore important to ensure that participants’ views are accurately recorded with Likert type scales, which can vary in the number of categories used.
Several researchers found that the 7-point scale may perform or represent the participants’ true views better than the 5-point scale <span class="citation">(Finstad, 2010; Joshi, Kale, Chandel, &amp; Pal, 2015)</span>.
While <span class="citation">Groves et al. (2009)</span> recommends using a 5 or 7-point Likert scale with a label for every scale point for attitude questions, participants often preferred more categories, such as 7, 9, or 10 <span class="citation">(Komorita &amp; Graham, 1965; Preston &amp; Colman, 2000)</span>.
However, <span class="citation">Preston &amp; Colman (2000)</span> found that reliability decreased with more than 10 categories.
This indicates that 7, 9, or 10 point scales should be adequate for reliable responses that accurately represent the participant’s views.
In addition, <span class="citation">DeCastellarnau (2018)</span> found that asking participants to respond to specific items (such as reliable - unreliable) is preferred over using a generalized agree - disagree scale in terms of measurement quality, cognitive effort, and bias.</p>
<p>Other methods have also been used to evaluate participant responses, such as asking participants to give a likelihood ratio, probability, or chance of guilt.
<span class="citation">Thompson, Kaasa, &amp; Peterson (2013)</span> asked participants rate the chance of guilt with values generally on a log 10 scale (ex. 1 in 100; 1 in 1,000); a middle value of a fifty-fifty chance; and extreme values of “Certain to be guilty” and “Impossible that he is guilty”.
They compared results from participants to Bayesian conditional probabilities based on provided likelihoods of a match and error rates in order to consider how much weight participants were giving DNA evidence.
Their results mainly showed no significant difference between Bayesian and participant estimates (meaning that the estimates were “in the right ballpark”), with some conditions producing estimates either greater than or less than what was expected.</p>
<p>In another study of the relationship between how examiners present evidence (likelihood ratio, verbal equivalent, or random match probability), <span class="citation">Thompson &amp; Newman (2015)</span> applied the same multiple choice scale for selecting the chance that the defendant committed the crime for half of the participants, while the other half of the participants were asked to supply how many more times likely it was that the defendant was guilty as compared to not guilty, or vice versa (based on a response scale found in <span class="citation">Martire et al. (2013)</span>).
The likelihood statement was worded as follows: “Based on the available evidence I believe it is ___ times more likely that Mr. Kelly is guilty than not guilty.” <span class="citation">(Thompson &amp; Newman, 2015)</span>.
<!-- [@thompsonLayUnderstanding, 5]. -->
In comparing responses from these two scales, <span class="citation">Thompson &amp; Newman (2015)</span> found that individuals were more likely to give higher estimates on the categorical log scale than when they were asked to provide a likelihood - resulting in the categorical log scale being more consistent with the expected result when using Bayesian methods of calculation.
This indicates an inconsistency in results based on the response method used, so response method must be carefully considered as a part of study design.</p>
</div>
<div id="conclusion" class="section level2 hasAnchor" number="1.6">
<h2><span class="header-section-number">1.6</span> Conclusion<a href="index.html#conclusion" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In order to ensure that the US justice system is just, we must be confident that the evidence presented in the courtroom is scientifically valid, and that the evidence is presented in a way that gives jurors the ability to appropriately judge its strength.
This includes the use of accurate error rates as well as quantitative responses.
One way to facilitate error rate calculation and quantitative results is through the use of algorithmic or statistical methods.
These methods must, however, be explained in a manner that is understandable to those without a statistical background, while limiting any of the potentially biasing effects of “truthiness” when using demonstrative evidence.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>

<a href="2-study1.html" class="navigation navigation-next navigation-unique" aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": [["thesis.pdf", "PDF"], ["thesis.epub", "EPUB"], ["thesis.docx", "Word"]],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"style": "style.css"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
